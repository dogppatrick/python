{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import date, time, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fp_pre:\n",
    "    def __init__(self,fn_weather, fn_price):\n",
    "        self.r_data = pd.read_csv(fn_weather, encoding=\"utf-8\")\n",
    "        self.lc_d = pd.read_csv(\"../lunar_celeb_date.csv\", encoding=\"utf-8\")\n",
    "        self.df_pbw = pd.read_csv(fn_price, encoding=\"utf-8\")\n",
    "        self.d_data = self.r_data[\"Date\"]\n",
    "    \n",
    "    \n",
    "    def prep_rdata(self):\n",
    "        r_data = self.r_data\n",
    "        col_fix =  ['T.Max', 'T.Min', 'Precp','Temperature', 'RH', 'StnPres', 'WS', 'WSGust']\n",
    "        for col in col_fix:\n",
    "            old = r_data[col]\n",
    "            new = []\n",
    "            for i in range(len(old)):\n",
    "                try:\n",
    "                    new.append(float(old[i]))\n",
    "                    tmp = float(old[i])\n",
    "                except ValueError:\n",
    "                    new.append(tmp)\n",
    "            r_data[col] = new\n",
    "        d_tmp = r_data['T.Max'] - r_data['T.Min']\n",
    "        r_data[\"d_tmp\"]= d_tmp\n",
    "        drop_c =[\"Date\",'T.Max', 'T.Min']\n",
    "        r_data = r_data.drop(columns=drop_c)\n",
    "        \n",
    "        def to_zscore(df):\n",
    "            col_x = df.columns.to_list()\n",
    "            mean = df.mean(axis=0)\n",
    "            std = df.std(axis=0)\n",
    "            for i in range(len(col_x)):\n",
    "                df[col_x[i]]=(df[col_x[i]]-mean[i])/std[i]\n",
    "            return  df , (mean, std)\n",
    "        r_data, self.recordz = to_zscore(r_data)\n",
    "        self.r_data = r_data\n",
    "    \n",
    "    \n",
    "    def join_lunar(self):\n",
    "        self.r_data[\"Date\"] = self.d_data\n",
    "        self.r_data = self.r_data.join(self.lc_d.set_index(\"date\"), on=\"Date\")\n",
    "        self.r_data = self.r_data.drop(columns=\"Date\")\n",
    "    \n",
    "    \n",
    "    def shift_rdata(self, shift1, shift2):\n",
    "        dfs =[]\n",
    "        arr_all =[]\n",
    "        if shift2==0:\n",
    "            df_s = self.r_data.copy()\n",
    "        else:\n",
    "            df_s = self.r_data.copy()\n",
    "            df_s = df_s.shift(periods=shift2)\n",
    "        arr_all = np.array(df_s)\n",
    "\n",
    "        for i in range(1,shift1):\n",
    "            tp = np.array(df_s.shift(periods=i))\n",
    "            arr_all = np.concatenate((arr_all, tp), axis=1)\n",
    "        df_all = pd.DataFrame(arr_all)\n",
    "        df_all[\"date\"] = self.d_data\n",
    "        df_all = df_all.dropna()\n",
    "        df_all = df_all.reset_index()\n",
    "        df_all = df_all.drop(columns=\"index\")\n",
    "        self.d_data = df_all[\"date\"]\n",
    "        self.r_data = df_all\n",
    "    \n",
    "    \n",
    "    def cutyw_rdata(self):\n",
    "        def trans_to_y_w(d_date):\n",
    "            year = int(d_date.split(\"-\")[0])\n",
    "            d_day = date(year,int(d_date.split(\"-\")[1]), int(d_date.split(\"-\")[2]))- date(year, 1, 1)\n",
    "            d_w = 1+ (d_day.days // 7)\n",
    "            if d_w ==53:\n",
    "                d_w = 52\n",
    "            result =  str(year) + \"_\" + str(d_w)\n",
    "\n",
    "            if d_day.days % 7 ==6:\n",
    "                return result\n",
    "            else:\n",
    "                return np.nan\n",
    "        y_w = []\n",
    "        for i in range(len(self.d_data)):\n",
    "            y_w.append(trans_to_y_w(self.d_data[i]))\n",
    "        self.r_data[\"y_w\"] = y_w\n",
    "        self.r_data = self.r_data.dropna()\n",
    "        self.r_data = self.r_data.reset_index()\n",
    "        self.r_data = self.r_data.drop(columns=\"index\")\n",
    "    \n",
    "    \n",
    "    def join_pbw_r_data(self):\n",
    "#         df_join = self.df_pbw.join(self.r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "        df_join = self.df_pbw.join(self.r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "        df_join = df_join.dropna()\n",
    "        df_join = df_join.reset_index()\n",
    "        df_join = df_join.drop(columns=\"index\")\n",
    "        self.r_data = df_join\n",
    "    \n",
    "    \n",
    "    def dummy_market(self,d_t_dummy):\n",
    "        tmp_dum = pd.DataFrame()\n",
    "        for col in d_t_dummy:\n",
    "            tmp_dum[col] = self.r_data[col]\n",
    "            dummy = pd.get_dummies(tmp_dum[col])\n",
    "            self.r_data = pd.concat([self.r_data, dummy], axis=1)\n",
    "        self.r_data = self.r_data.drop(columns=d_t_dummy)\n",
    "        self.x = self.r_data\n",
    "#         [,\"year\", \"week\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "    \n",
    "    \n",
    "    def drop_x_data(self,drop_c):\n",
    "        self.x = self.x.drop(columns=drop_c)\n",
    "        self.input_units = self.x.shape[1]\n",
    "    \n",
    "    \n",
    "    def all_prep(self, shift1, shift2,d_t_dummy):\n",
    "        self.prep_rdata()\n",
    "        self.join_lunar()\n",
    "        self.shift_rdata(shift1, shift2)\n",
    "        self.shift1 = shift1\n",
    "        self.shift2 = shift2\n",
    "        self.cutyw_rdata()\n",
    "        self.join_pbw_r_data()\n",
    "        self.dummy_market(d_t_dummy)\n",
    "        self.extract_xy()\n",
    "    \n",
    "    \n",
    "    def extract_xy(self):\n",
    "#     y_date = df_join[\"date\"]\n",
    "        self.y_yw = self.r_data[\"y_w\"]\n",
    "        self.y_raw = np.array(self.r_data[\"price_diff\"])\n",
    "        \n",
    "    \n",
    "    \n",
    "    def y_to_class(self, list_y_class=[-0.1,0,0.1]):\n",
    "        y_raw = self.y_raw\n",
    "        self.y_list_class = list_y_class\n",
    "        y_class = []\n",
    "        for i in range(len(y_raw)):\n",
    "            c = 0\n",
    "            y = y_raw[i]\n",
    "            for j in range(len(list_y_class)):\n",
    "                if y > list_y_class[j]:\n",
    "                    c = c +1\n",
    "            y_class.append(c)\n",
    "        self.y_class = np.array(y_class)\n",
    "        self.y_freq = (np.bincount(y_class), list_y_class)\n",
    "        self.output_class =len(np.bincount(y_class))\n",
    "    \n",
    "    \n",
    "    def split_data(self, year):\n",
    "        y_w = self.y_yw\n",
    "        y_year = []\n",
    "        for  i in range(len(y_w)):\n",
    "            y_year.append(int(y_w[i].split(\"_\")[0]))\n",
    "        y_year = np.array(y_year)\n",
    "        self.split_info = np.unique(np.array(y_year), return_counts=True)\n",
    "        b_train = y_year[:]<=year\n",
    "        b_test = y_year[:]>year\n",
    "        x = np.array(self.x)\n",
    "        y = np.array(self.y_class)\n",
    "        self.split_xy = (x[b_train,:], y[b_train] , x[b_test,:], y[b_test])\n",
    "    \n",
    "    def model_build(self, dinp, epochs):\n",
    "        x_train, y_train, x_test, y_test = self.split_xy\n",
    "        model = Sequential()\n",
    "        layer_0 = Dense(units =self.input_units//dinp, input_dim = self.input_units,\n",
    "                        kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "        model.add(layer_0)\n",
    "        model.add(Dropout(0.25))\n",
    "        layer_1 = Dense(units =self.input_units//(dinp*10),\n",
    "                        kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "        model.add(layer_1)\n",
    "        model.add(Dropout(0.25))\n",
    "#         layer_1 = Dense(units =(self.shift1+1),kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "#         model.add(layer_1)\n",
    "#         model.add(Dropout(0.25))\n",
    "        layer_out = Dense(units = self.output_class,kernel_initializer = \"random_normal\", \n",
    "                          activation = \"softmax\")\n",
    "        model.add(layer_out)\n",
    "        #     model.summary()\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "        self.train_model = model\n",
    "\n",
    "    def model_test(self):\n",
    "        x_train, y_train, x_test, y_test = self.split_xy\n",
    "        train_history = self.train_model.fit(x = x_train, y = np_utils.to_categorical(y_train), \n",
    "                                  validation_split = 0.1, epochs =epochs, verbose = 0)\n",
    "        pre = self.train_model.predict_classes(x_test)\n",
    "        acc = round(accuracy_score(y_test, pre)*100,2)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../result/merge_weather\\C0F9L0_后里.csv ../result/flower_price_byweek\\Anthurium_pbyweek.csv\n"
     ]
    }
   ],
   "source": [
    "w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "# 修改 select_t 可以拿不同測站 vs花花朵\n",
    "st, flower = select_t[0]\n",
    "fn_weather = w_list[st]\n",
    "fn_price = p_list[flower]\n",
    "print(fn_weather, fn_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bullid class 讀取檔案\n",
    "fp = fp_pre(fn_weather, fn_price)\n",
    "# 花價格 + 天氣 + 節日後刪除資料\n",
    "drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# 目前轉成 one-hot encoding 的資料\n",
    "d_t_dummy = [\"market\", \"week\"]\n",
    "# 設定數字 (總共要取幾天的資料,挑過幾天( 8 則跳兩週)\n",
    "fp.all_prep(28,1,d_t_dummy)\n",
    "fp.drop_x_data(drop_c)\n",
    "# 設定結果 y pct_change 切分點 [-0.1 ,0, 0.1] 則切成 [-0.1以下, -0.1 ~ 0,0 ~ 0.1, 0.1 以上]\n",
    "fp.y_to_class([-0.1,0,0.1])\n",
    "fp.split_data(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t29.02\t29.8\t32.94\t29.8\t33.73\t\n",
      "3\t32.16\t31.76\t32.55\t30.98\t30.59\t\n",
      "4\t32.94\t30.2\t29.41\t30.98\t30.59\t\n",
      "5\t32.55\t30.59\t30.98\t28.63\t28.24\t\n",
      "6\t30.59\t33.73\t32.16\t30.59\t32.16\t\n",
      "7\t31.37\t30.98\t32.94\t29.8\t27.06\t\n",
      "8\t27.45\t30.2\t29.8\t31.76\t28.24\t\n",
      "9\t34.51\t31.37\t32.94\t31.37\t32.16\t\n"
     ]
    }
   ],
   "source": [
    "for dinp in range(2,10):\n",
    "    print(dinp, end=\"\\t\")\n",
    "    fp.model_build(dinp, 5)\n",
    "    for run_times in range(5):\n",
    "#         print(epochs, end=\"\\t\")\n",
    "        print(fp.model_test(), end=\"\\t\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
