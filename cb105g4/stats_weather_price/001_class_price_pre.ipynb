{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../result/merge_weather\\\\467480_嘉義.csv', '../result/merge_weather\\\\C0F9L0_后里.csv', '../result/merge_weather\\\\C0K490_古坑.csv', '../result/merge_weather\\\\C0X060_下營.csv']\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import date, time, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "print(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fp_pre:\n",
    "    def __init__(self,fn_weather, fn_price):\n",
    "        self.r_data = pd.read_csv(fn_weather, encoding=\"utf-8\")\n",
    "        self.lc_d = pd.read_csv(\"../lunar_done_new.csv\", encoding=\"utf-8\")\n",
    "        self.df_pbw = pd.read_csv(fn_price, encoding=\"utf-8\")\n",
    "        self.d_data = self.r_data[\"Date\"]\n",
    "        self.flower_name = fn_price.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "        self.station_name = fn_weather.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "    \n",
    "    def market_select(self, market):\n",
    "        self.df_pbw = self.df_pbw.groupby(\"market\").get_group(market)\n",
    "    \n",
    "    def prep_rdata(self):\n",
    "        r_data = self.r_data\n",
    "        col_fix =  ['T.Max', 'T.Min', 'Precp','Temperature', 'RH', 'StnPres', 'WS', 'WSGust']\n",
    "        for col in col_fix:\n",
    "            old = r_data[col]\n",
    "            new = []\n",
    "            for i in range(len(old)):\n",
    "                try:\n",
    "                    new.append(float(old[i]))\n",
    "                    tmp = float(old[i])\n",
    "                except ValueError:\n",
    "                    new.append(tmp)\n",
    "            r_data[col] = new\n",
    "        d_tmp = r_data['T.Max'] - r_data['T.Min']\n",
    "        r_data[\"d_tmp\"]= d_tmp\n",
    "        drop_c =[\"Date\",'T.Max', 'T.Min']\n",
    "        r_data = r_data.drop(columns=drop_c)\n",
    "        \n",
    "        def to_zscore(df):\n",
    "            col_x = df.columns.to_list()\n",
    "            mean = df.mean(axis=0)\n",
    "            std = df.std(axis=0)\n",
    "            for i in range(len(col_x)):\n",
    "                df[col_x[i]]=(df[col_x[i]]-mean[i])/std[i]\n",
    "            return  df , [list(mean), list(std)]\n",
    "        r_data, self.recordz = to_zscore(r_data)\n",
    "        self.r_data = r_data\n",
    "        self.r_data_pre_done = r_data\n",
    "    \n",
    "    \n",
    "    def join_lunar(self):\n",
    "        self.r_data[\"Date\"] = self.d_data\n",
    "        self.r_data = self.r_data.join(self.lc_d.set_index(\"date\"), on=\"Date\")\n",
    "        self.r_data = self.r_data.drop(columns=\"Date\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    def shift_rdata(self, shift1, shift2):\n",
    "        dfs =[]\n",
    "        arr_all =[]\n",
    "        if shift2==0:\n",
    "            df_s = self.r_data.copy()\n",
    "        else:\n",
    "            df_s = self.r_data.copy()\n",
    "            df_s = df_s.shift(periods=shift2)\n",
    "        arr_all = np.array(df_s)\n",
    "\n",
    "        for i in range(1,shift1):\n",
    "            tp = np.array(df_s.shift(periods=i))\n",
    "            arr_all = np.concatenate((arr_all, tp), axis=1)\n",
    "        df_all = pd.DataFrame(arr_all)\n",
    "        df_all[\"date\"] = self.d_data\n",
    "        df_all = df_all.dropna()\n",
    "        df_all = df_all.reset_index()\n",
    "        df_all = df_all.drop(columns=\"index\")\n",
    "        self.d_data = df_all[\"date\"]\n",
    "        self.r_data = df_all\n",
    "    \n",
    "    \n",
    "    def cutyw_rdata(self):\n",
    "        def trans_to_y_w(d_date):\n",
    "            year = int(d_date.split(\"-\")[0])\n",
    "            d_day = date(year,int(d_date.split(\"-\")[1]), int(d_date.split(\"-\")[2]))- date(year, 1, 1)\n",
    "            d_w = 1+ (d_day.days // 7)\n",
    "            if d_w ==53:\n",
    "                d_w = 52\n",
    "            result =  str(year) + \"_\" + str(d_w)\n",
    "\n",
    "            if d_day.days % 7 ==6:\n",
    "                return result\n",
    "            else:\n",
    "                return np.nan\n",
    "        y_w = []\n",
    "        for i in range(len(self.d_data)):\n",
    "            y_w.append(trans_to_y_w(self.d_data[i]))\n",
    "        self.r_data[\"y_w\"] = y_w\n",
    "        self.r_data_n_drop = self.r_data.copy()\n",
    "        self.r_data = self.r_data.dropna()\n",
    "        self.r_data = self.r_data.reset_index(drop=True)\n",
    "        self.cy_data = self.d_data\n",
    "\n",
    "    \n",
    "    \n",
    "    def join_pbw_r_data(self):\n",
    "        df_join = self.df_pbw.join(self.r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "        df_join = df_join.dropna()\n",
    "        df_join = df_join.reset_index(drop=True)\n",
    "#         df_join = df_join.drop(columns=\"index\")\n",
    "        self.d_data = df_join[\"date\"]\n",
    "        self.r_data = df_join\n",
    "    \n",
    "    \n",
    "    def dummy_market(self,d_t_dummy):\n",
    "        tmp_dum = pd.DataFrame()\n",
    "        for col in d_t_dummy:\n",
    "            tmp_dum[col] = self.r_data[col]\n",
    "            dummy = pd.get_dummies(tmp_dum[col])\n",
    "            self.r_data = pd.concat([self.r_data, dummy], axis=1)\n",
    "        self.r_data = self.r_data.drop(columns=d_t_dummy)\n",
    "        self.x = self.r_data\n",
    "        self.dummy = dummy\n",
    "#         [,\"year\", \"week\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "    \n",
    "    \n",
    "    def drop_x_data(self,drop_c):\n",
    "        self.x_beforedrop = self.x\n",
    "        self.y_raw_price = self.x[\"w_avg\"]\n",
    "        self.x = self.x.drop(columns=drop_c)\n",
    "        self.input_units = self.x.shape[1]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def all_prep(self, shift1, shift2,d_t_dummy):\n",
    "        self.prep_rdata()\n",
    "        self.join_lunar()\n",
    "        self.shift_rdata(shift1, shift2)\n",
    "        self.shift1 = shift1\n",
    "        self.shift2 = shift2\n",
    "        self.cutyw_rdata()\n",
    "        self.join_pbw_r_data()\n",
    "        self.dummy_market(d_t_dummy)\n",
    "        self.extract_xy()\n",
    "        \n",
    "    def all_prep_market_select(self, shift1, shift2,d_t_dummy,market):\n",
    "        self.market_select(market)\n",
    "        self.prep_rdata()\n",
    "        self.join_lunar()\n",
    "        self.shift_rdata(shift1, shift2)\n",
    "        self.shift1 = shift1\n",
    "        self.shift2 = shift2\n",
    "        self.cutyw_rdata()\n",
    "        self.join_pbw_r_data()\n",
    "        self.dummy_market(d_t_dummy)\n",
    "        self.extract_xy()\n",
    "    \n",
    "    def all_prep_nolunar(self, shift1, shift2,d_t_dummy):\n",
    "        self.prep_rdata()\n",
    "#         self.join_lunar()\n",
    "        self.shift_rdata(shift1, shift2)\n",
    "        self.shift1 = shift1\n",
    "        self.shift2 = shift2\n",
    "        self.cutyw_rdata()\n",
    "        self.join_pbw_r_data()\n",
    "        self.dummy_market(d_t_dummy)\n",
    "        self.extract_xy()\n",
    "    \n",
    "    def extract_xy(self):\n",
    "#     y_date = df_join[\"date\"]\n",
    "        self.y_yw = self.r_data[\"y_w\"]\n",
    "        self.y_raw = np.array(self.r_data[\"price_diff\"])\n",
    "        self.y_diff_d = np.array(self.r_data[\"w_avg\"].diff())\n",
    "        \n",
    "    def split_y_to_class(self, input_y, list_y_class=[0]):\n",
    "        y_class = []\n",
    "        for i in range(len(input_y)):\n",
    "            c = 0\n",
    "            y = input_y[i]\n",
    "            for j in range(len(list_y_class)):\n",
    "                if y > list_y_class[j]:\n",
    "                    c = c +1\n",
    "            y_class.append(c)\n",
    "#         print((np.bincount(y_class), list_y_class))\n",
    "        self.output_class = len(np.bincount(y_class))\n",
    "        return np.array(y_class)\n",
    "    \n",
    "    def y_to_class(self, list_y_class=[-0.1,0,0.1]):\n",
    "        y_raw = self.y_raw\n",
    "        self.y_list_class = list_y_class\n",
    "        y_class = []\n",
    "        for i in range(len(y_raw)):\n",
    "            c = 0\n",
    "            y = y_raw[i]\n",
    "            for j in range(len(list_y_class)):\n",
    "                if y > list_y_class[j]:\n",
    "                    c = c +1\n",
    "            y_class.append(c)\n",
    "        self.y_class = np.array(y_class)\n",
    "        self.y_freq = (np.bincount(y_class), list_y_class)\n",
    "        self.output_class =len(np.bincount(y_class))\n",
    "    \n",
    "    \n",
    "    def split_data(self, year,year_s=0):\n",
    "        y_w = self.y_yw\n",
    "        y_raw = self.y_raw\n",
    "        y_year = []\n",
    "        for  i in range(len(y_w)):\n",
    "            y_year.append(int(y_w[i].split(\"_\")[0]))\n",
    "        y_year = np.array(y_year)\n",
    "        self.split_info = np.unique(np.array(y_year), return_counts=True)\n",
    "#         b_train = y_year[:]<=year\n",
    "#         b_test = y_year[:]>year\n",
    "#         delete data before year_s\n",
    "        b_train = (y_year[:]<=year) * (y_year[:]>=year_s)\n",
    "        b_test = (y_year[:]>year) * (y_year[:]>=year_s)\n",
    "        x = np.array(self.x)\n",
    "        y = np.array(self.y_class)\n",
    "        self.split_xy = (x[b_train,:], y[b_train] , x[b_test,:], y[b_test])\n",
    "        self.split_xy_count = (x[b_train,:], y_raw[b_train] , x[b_test,:], y_raw[b_test])\n",
    "    \n",
    "    def model_build(self, dinp=5):\n",
    "        x_train, y_train, x_test, y_test = self.split_xy\n",
    "        model = Sequential()\n",
    "        layer_0 = Dense(units =self.input_units//dinp, input_dim = self.input_units,\n",
    "                        kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "        model.add(layer_0)\n",
    "        model.add(Dropout(0.35))\n",
    "        layer_1 = Dense(units =self.input_units//(dinp*5),\n",
    "                        kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "        model.add(layer_1)\n",
    "        model.add(Dropout(0.35))\n",
    "        layer_out = Dense(units = self.output_class,kernel_initializer = \"random_normal\", \n",
    "                          activation = \"softmax\")\n",
    "        model.add(layer_out)\n",
    "        #     model.summary()\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "        self.train_model = model\n",
    "\n",
    "    def model_test(self, epochs=10):\n",
    "        x_train, y_train, x_test, y_test = self.split_xy\n",
    "        x_train, x_train_d, y_train, y_train_d = train_test_split(x_train, y_train,  test_size=0.01, shuffle=True)\n",
    "        train_history = self.train_model.fit(x = x_train, y = np_utils.to_categorical(y_train), \n",
    "                                             validation_split = 0.2, epochs =epochs, verbose = 0)\n",
    "        pre = self.train_model.predict_classes(x_test)\n",
    "        acc = round(accuracy_score(y_test, pre)*100,2)\n",
    "        test_result =  (pre , y_test)\n",
    "        in_acc = round(accuracy_score(self.train_model.predict_classes(x_train), y_train)*100,2)\n",
    "        train_result = (self.train_model.predict_classes(x_train), y_train)\n",
    "        return acc,test_result, in_acc,train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list = glob.glob(\"./flower_pre_model/04_model/*_15_c*\")\n",
    "# m_fn = model_list[0]\n",
    "# # for m_fn in model_list:\n",
    "# flower = m_fn.split(\"\\\\\")[1].split(\"_\")[0]\n",
    "# station = m_fn.split(\"\\\\\")[1].split(\"_\")[1]\n",
    "# shift1 =  int(m_fn.split(\"\\\\\")[1].split(\"_\")[2])\n",
    "# shift2 = 15\n",
    "# y_class_list = [-0.1,0,0.1]\n",
    "# fn_weather = glob.glob(\"../result/merge_weather/\"+ station +\"*.csv\")[0]\n",
    "# fn_price  = glob.glob(\"../result/flower_price_byweek/\"+ flower + \"*.csv\")[0]\n",
    "\n",
    "# fp = fp_pre(fn_weather, fn_price)\n",
    "# drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# d_t_dummy = [\"market\",\"week\"]\n",
    "# fp.all_prep(shift1,shift2,d_t_dummy)\n",
    "# # fp.y_to_class(y_class_list)\n",
    "# # fp.drop_x_data(drop_c)\n",
    "# # model = load_model(m_fn)\n",
    "\n",
    "# # pre  = model.predict_classes(fp.x)\n",
    "# # df = pd.DataFrame()\n",
    "# # df[\"date\"] = fp.d_data\n",
    "# # df[\"price\"]=fp.y_raw_price\n",
    "# # # 先給值再覆蓋\n",
    "# # df[\"pre_price\"]=fp.y_raw_price\n",
    "# # df[\"pre\"]=pre\n",
    "# # df[\"ans\"]=fp.y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = glob.glob(\"./flower_pre_model/04_model/*_15_c*\")\n",
    "# m_fn = model_list[0]\n",
    "for m_fn in model_list:\n",
    "    flower = m_fn.split(\"\\\\\")[1].split(\"_\")[0]\n",
    "    station = m_fn.split(\"\\\\\")[1].split(\"_\")[1]\n",
    "    shift1 =  int(m_fn.split(\"\\\\\")[1].split(\"_\")[2])\n",
    "    shift2 = 15\n",
    "    y_class_list = [-0.1,0,0.1]\n",
    "    fn_weather = glob.glob(\"../result/merge_weather/\"+ station +\"*.csv\")[0]\n",
    "    fn_price  = glob.glob(\"../result/flower_price_byweek/\"+ flower + \"*.csv\")[0]\n",
    "\n",
    "    fp = fp_pre(fn_weather, fn_price)\n",
    "    drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "    d_t_dummy = [\"market\",\"week\"]\n",
    "    fp.all_prep(shift1,shift2,d_t_dummy)\n",
    "    fp.y_to_class(y_class_list)\n",
    "    fp.drop_x_data(drop_c)\n",
    "    model = load_model(m_fn)\n",
    "\n",
    "    pre  = model.predict_classes(fp.x)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"date\"] = fp.d_data\n",
    "    df[\"price\"]=fp.y_raw_price\n",
    "    # 先給值再覆蓋\n",
    "    df[\"pre_price\"]=fp.y_raw_price\n",
    "    df[\"pre\"]=pre\n",
    "    df[\"ans\"]=fp.y_class\n",
    "    m_list = [\"台中\", \"台北\", \"台南\", \"彰化\", \"高雄\"]\n",
    "    for m in m_list:\n",
    "        df[m] = fp.x[m]\n",
    "\n",
    "    price = np.array(df[\"price\"])\n",
    "    pre  = np.array(df[\"pre\"])\n",
    "    pre_price = []\n",
    "\n",
    "    c = [0.9,0.95,1.05,1.1]\n",
    "    for i in range(len(price)):\n",
    "        pre_price.append(price[i]*c[pre[i]])\n",
    "    df[\"pre_price\"]=pre_price\n",
    "    df[\"pre_price\"] = df[\"pre_price\"].shift(periods=1)\n",
    "\n",
    "    arr_m = np.array(df)[:,5:5+5]\n",
    "    market_list = [\"台中\",\"台北\",\"台南\",\"彰化\",\"高雄\"]\n",
    "    m_new = arr_m * market_list\n",
    "    m_done = []\n",
    "    for d in m_new:\n",
    "        m_done.append(\"\".join(d))\n",
    "    df[\"market\"] = m_done\n",
    "    df = df.drop(columns=market_list)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    tags = [\"大跌\",\"小跌\",\"小漲\",\"大漲\"]\n",
    "    pre = np.array(df[\"pre\"]).astype(str)\n",
    "    ans = np.array(df[\"ans\"]).astype(str)\n",
    "    for i in range(len(tags)):\n",
    "        pre[pre==str(i)]=tags[i] \n",
    "        ans[ans==str(i)]=tags[i]\n",
    "    df[\"pre\"]=pre\n",
    "    df[\"ans\"]=ans\n",
    "    # df.head(20)\n",
    "    fn_save = \"../result/predict_result/\" + flower + \".csv\"\n",
    "    df.to_csv(fn_save, encoding=\"utf-8\", index=False, header=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_info = {}\n",
    "# w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "# p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "# select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "# st, flower = select_t[3]\n",
    "# fn_weather = w_list[st]\n",
    "# fn_price = p_list[flower]\n",
    "# print(fn_weather, fn_price)\n",
    "# fp = fp_pre(fn_weather, fn_price)\n",
    "# drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# d_t_dummy = [\"market\",\"week\"]\n",
    "# # fp.all_prep(12,1,d_t_dummy)\n",
    "# fp.all_prep(11,1,d_t_dummy)\n",
    "# fp.y_to_class([-0.1,0,0.1])\n",
    "# # fp.y_to_class([0])\n",
    "# fp.drop_x_data(drop_c)\n",
    "# fp.x.shape,fp.y_yw.shape,fp.y_class.shape\n",
    "# model = load_model(\"./flower_pre_model/04_model/OrientalLily_C0K490_11_1_c4.h5\")\n",
    "# # model = load_model(\"./flower_pre_model/01_model/OrientalLily_C0K490_12_1.h5\")\n",
    "# # x_train, y_train, x_test, y_test = fp.split_xy\n",
    "# pre  = model.predict_classes(fp.x)\n",
    "# df = pd.DataFrame()\n",
    "# df[\"pre\"]=pre\n",
    "# # df[\"y_yw\"]=fp.y_yw\n",
    "# df[\"ans\"]=fp.y_class\n",
    "# df[\"price\"]=fp.y_raw_price\n",
    "# df[\"date\"] = fp.d_data\n",
    "# m_list = [\"台中\", \"台北\", \"台南\", \"彰化\", \"高雄\"]\n",
    "# for m in m_list:\n",
    "#     df[m] = fp.x[m]\n",
    "# df.head()\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# df[\"pre\"]=pre\n",
    "# # df[\"y_yw\"]=fp.y_yw\n",
    "# df[\"ans\"]=fp.y_class\n",
    "# df[\"price\"]=fp.y_raw_price\n",
    "# df[\"date\"] = fp.d_data\n",
    "# m_list = [\"台中\", \"台北\", \"台南\", \"彰化\", \"高雄\"]\n",
    "# for m in m_list:\n",
    "#     df[m] = fp.x[m]\n",
    "# # df.to_csv(\"result_to_plot.csv\", index=False)\n",
    "# # df.to_csv(\"test0529.csv\",index=False)\n",
    "# price = np.array(df[\"price\"])\n",
    "# pre  = np.array(df[\"pre\"])\n",
    "# pre_price = []\n",
    "\n",
    "# c = [0.9,0.95,1.05,1.1]\n",
    "# for i in range(len(price)):\n",
    "#     pre_price.append(price[i]*c[pre[i]])\n",
    "# df[\"pre_price\"]=pre_price\n",
    "# df[\"pre_price\"] = df[\"pre_price\"].shift(periods=1)\n",
    "# # df.head(5)\n",
    "# arr = np.array(df)\n",
    "# arr = arr[arr[:,7]==1]\n",
    "# # arr = arr[-80:]\n",
    "# df_m_s= pd.DataFrame(arr,columns=df.columns.to_list())\n",
    "# df_m_s\n",
    "# # df_new = df_m_s[[\"price\", \"pre_price\"]]\n",
    "# # mse = mean_squared_error(df_new[\"price\"], df_new[\"pre_price\"])\n",
    "\n",
    "# # print(best_mse, best_t)\n",
    "# # arr = arr[:,0:4]\n",
    "# # plt.plot(range(len(df_new)),df_new[\"price\"])\n",
    "# # plt.plot(range(len(df_new)),df_new[\"pre_price\"])\n",
    "# # df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m = pd.DataFrame()\n",
    "# m_list = [\"台中\", \"台北\", \"台南\", \"彰化\", \"高雄\"]\n",
    "# for m in m_list:\n",
    "#     df[m] = fp.x[m]\n",
    "# df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(20)\n",
    "# # m = m_list[0]\n",
    "# arr = np.array(df)\n",
    "# # select m \n",
    "# arr = arr[arr[:,5]==1]\n",
    "# arr = arr[:,0:4]\n",
    "# arr[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # arr = np.array(df)\n",
    "# green = arr[arr[:,0]==0]\n",
    "# red = arr[arr[:,0]==1]\n",
    "# plt.plot(green[:,3],green[:,2])\n",
    "# plt.plot(red[:,3],red[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_info = {}\n",
    "# w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "# p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "# select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "# st, flower = select_t[3]\n",
    "# fn_weather = w_list[st]\n",
    "# fn_price = p_list[flower]\n",
    "# fp = fp_pre(fn_weather, fn_price)\n",
    "# model_info[\"flower\"]= fp.flower_name\n",
    "# model_info[\"station\"]= fp.station_name\n",
    "# drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# d_t_dummy = [\"market\"]\n",
    "# fp.all_prep(1,1,d_t_dummy)\n",
    "# fp.dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "# p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "# # st = 0\n",
    "# records = pd.DataFrame()\n",
    "# for st in range(4):\n",
    "#     fn_weather = w_list[st]\n",
    "#     st_n  = fn_weather.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "#     fn_price = p_list[0]\n",
    "#     print(fn_weather, fn_price)\n",
    "#     fp = fp_pre(fn_weather, fn_price)\n",
    "#     fp.prep_rdata()\n",
    "#     records[st_n] = fp.recordz\n",
    "# records\n",
    "# records.to_csv(\"./flower_pre_model/weather_trans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main_model_run(select,year_split,shift1, shift2, list_split_y):\n",
    "# #     class_y_diff =[0]\n",
    "#     model_info = {}\n",
    "#     w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "#     p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "#     select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "#     st, flower = select_t[select]\n",
    "#     fn_weather = w_list[st]\n",
    "#     fn_price = p_list[flower]\n",
    "#     fp = fp_pre(fn_weather, fn_price)\n",
    "#     model_info[\"flower\"]= fp.flower_name\n",
    "#     model_info[\"station\"]= fp.station_name\n",
    "#     drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "#     d_t_dummy = [\"market\", \"week\"]\n",
    "#     fp.all_prep(shift1, shift2,d_t_dummy)\n",
    "# #     fp.y_to_class(list_split_y)\n",
    "#     fp.y_to_class(list_split_y)\n",
    "#     fp.drop_x_data(drop_c)\n",
    "    \n",
    "#     fp.split_data(year_split)\n",
    "#     model_info[\"weather_trans\"] = fp.recordz\n",
    "#     model_info[\"shift\"] = (shift1, shift2)\n",
    "#     dinp = 5\n",
    "#     acc = []\n",
    "#     epo_cf = []\n",
    "#     acc_max = 0\n",
    "#     epochs = 3\n",
    "#     epochs_try =20\n",
    "#     plot_x = []\n",
    "#     fp.model_build(dinp)\n",
    "#     test_acc = []\n",
    "#     train_acc = []\n",
    "#     #         print(epochs, end=\"\\t\")\n",
    "#     for i in range(epochs_try):\n",
    "#         t_acc , test_result, in_acc,train_result= fp.model_test(epochs)\n",
    "#         acc.append(t_acc)\n",
    "#         if t_acc>acc_max and in_acc>50:\n",
    "#             acc_max = t_acc\n",
    "#             best_test = test_result\n",
    "#             in_acc_max  = in_acc\n",
    "#             best_train = train_result\n",
    "#             best_epochs = epochs*(i+1)\n",
    "#             best_mode = fp.train_model\n",
    "#         test_acc.append(t_acc)\n",
    "#         train_acc.append(in_acc)\n",
    "#     model_info[\"acc_info\"] = [acc_max, in_acc_max, best_epochs]\n",
    "# #     model_info.append(best_mode)\n",
    "#     return model_info, best_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_model_data =[]\n",
    "# save_path = \"./flower_pre_model/04_model/\"\n",
    "# select = 0\n",
    "# year_split = 2018\n",
    "# shift1 = 7\n",
    "# shift2 = 1\n",
    "\n",
    "# list_split_y = [-0.1,0,0.1]\n",
    "# for shift2 in [1,8,15]: # [1,8,15]:\n",
    "#     for select in range(5): \n",
    "#         best_test_acc = 0 \n",
    "#         for shift1 in range(7,16,2):\n",
    "#             records , best_model= main_model_run(select,year_split,shift1, shift2, list_split_y)\n",
    "#             model_fn = save_path + \"_\".join((records[\"flower\"], records[\"station\"], str(records[\"shift\"][0]),\n",
    "#                                              str(records[\"shift\"][1]))) + \"_c4.h5\"\n",
    "#             model_data  = [records[\"flower\"], records[\"station\"], str(records[\"shift\"][0]),\n",
    "#                            str(records[\"shift\"][1]), records['acc_info'][0], records['acc_info'][1]]\n",
    "#             if best_test_acc< records['acc_info'][0]:\n",
    "#                 best_test_acc = records['acc_info'][0]\n",
    "#                 best_model_save = best_model\n",
    "#                 best_model_fn = model_fn\n",
    "#             all_model_data.append(model_data)\n",
    "            \n",
    "#         best_model_save.save(best_model_fn)\n",
    "# pd.DataFrame(all_model_data, columns=[\"flower\", \"station\", \"shift1\", \"shift2\", \"test_acc\", \"train_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # records\n",
    "# df = pd.DataFrame(all_model_data, columns=[\"flower\", \"station\", \"shift1\", \"shift2\", \"test_acc\", \"train_acc\"])\n",
    "# df.to_csv(\"./flower_pre_model/04_model/result.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(all_model_data, columns=[\"flower\", \"station\", \"shift1\", \"shift2\", \"test_acc\", \"train_acc\"])\n",
    "# g = df.groupby([\"flower\",\"shift2\"])\n",
    "# best_data = []\n",
    "# for flower in [\"Anthurium\", \"Eustoma\", \"Chrysanthemum\",\"OrientalLily\",\"Rose\"]:\n",
    "#     for sh2 in [\"1\",\"8\",\"15\"]:\n",
    "#         df_t = g.get_group((flower,sh2))\n",
    "#         best_data.append(list(df_t.loc[df_t['test_acc'].idxmax()]))\n",
    "# df_b = pd.DataFrame(best_data, columns=['flower', 'station', 'shift1', 'shift2', 'test_acc', 'train_acc'])\n",
    "# df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_b.to_csv(\"./flower_pre_model/04_model/result_best.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select = 0\n",
    "# year_split = 2018\n",
    "# shift1 = 7\n",
    "# shift2 = 1\n",
    "# list_split_y = [0]\n",
    "# model_info = []\n",
    "# w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "# p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "# select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "# st, flower = select_t[select]\n",
    "# fn_weather = w_list[st]\n",
    "# fn_price = p_list[flower]\n",
    "# fp = fp_pre(fn_weather, fn_price)\n",
    "# model_info.append(fp.flower_name)\n",
    "# drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# d_t_dummy = [\"market\", \"week\"]\n",
    "# fp.all_prep(shift1, shift2,d_t_dummy)\n",
    "# fp.y_to_class(list_split_y)\n",
    "# fp.drop_x_data(drop_c)\n",
    "# fp.split_data(year_split, year_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_model_run(select,year_split,shift1, shift2, class_y_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 花名 測站名稱 shift (參數,預測週(1,8,15), 準確率範圍)\n",
    "# Anthurium 467480     shift:(14,1,55~63%), (27,8,46~65%) (19,15,55~72%)\n",
    "# Chrysanthemum C0F9L0 shift:(19,1,51~58%), (16,8,40~59%) (16,15,33~50%)\n",
    "# Eustoma C0F9L0       shift:(3,1,67~73%) (16,8,49~57%) (12,15,51~63%)  epochs [10,]\n",
    "# OrientalLily C0X060  shift:(17,1,77~79%) (22,8,66~75%) (14,15,43~64%) epochs [ , 12, ]\n",
    "# Rose C0X060          shift:(7,1,47~64%) (18,8,42~64%) (18,15,55~69%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
