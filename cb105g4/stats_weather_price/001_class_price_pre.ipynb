{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../result/merge_weather\\\\467480_嘉義.csv', '../result/merge_weather\\\\C0F9L0_后里.csv', '../result/merge_weather\\\\C0K490_古坑.csv', '../result/merge_weather\\\\C0X060_下營.csv']\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import date, time, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "print(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fp_pre:\n",
    "    def __init__(self,fn_weather, fn_price):\n",
    "        self.r_data = pd.read_csv(fn_weather, encoding=\"utf-8\")\n",
    "        self.lc_d = pd.read_csv(\"../lunar_done_new.csv\", encoding=\"utf-8\")\n",
    "        self.df_pbw = pd.read_csv(fn_price, encoding=\"utf-8\")\n",
    "        self.d_data = self.r_data[\"Date\"]\n",
    "        self.flower_name = fn_price.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "        self.station_name = fn_weather.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "    \n",
    "    def market_select(self, market):\n",
    "        self.df_pbw = self.df_pbw.groupby(\"market\").get_group(market)\n",
    "    \n",
    "    def prep_rdata(self):\n",
    "        r_data = self.r_data\n",
    "        col_fix =  ['T.Max', 'T.Min', 'Precp','Temperature', 'RH', 'StnPres', 'WS', 'WSGust']\n",
    "        for col in col_fix:\n",
    "            old = r_data[col]\n",
    "            new = []\n",
    "            for i in range(len(old)):\n",
    "                try:\n",
    "                    new.append(float(old[i]))\n",
    "                    tmp = float(old[i])\n",
    "                except ValueError:\n",
    "                    new.append(tmp)\n",
    "            r_data[col] = new\n",
    "        d_tmp = r_data['T.Max'] - r_data['T.Min']\n",
    "        r_data[\"d_tmp\"]= d_tmp\n",
    "        drop_c =[\"Date\",'T.Max', 'T.Min']\n",
    "        r_data = r_data.drop(columns=drop_c)\n",
    "        \n",
    "        def to_zscore(df):\n",
    "            col_x = df.columns.to_list()\n",
    "            mean = df.mean(axis=0)\n",
    "            std = df.std(axis=0)\n",
    "            for i in range(len(col_x)):\n",
    "                df[col_x[i]]=(df[col_x[i]]-mean[i])/std[i]\n",
    "            return  df , [list(mean), list(std)]\n",
    "        r_data, self.recordz = to_zscore(r_data)\n",
    "        self.r_data = r_data\n",
    "        self.r_data_pre_done = r_data\n",
    "    \n",
    "    \n",
    "    def join_lunar(self):\n",
    "        self.r_data[\"Date\"] = self.d_data\n",
    "        self.r_data = self.r_data.join(self.lc_d.set_index(\"date\"), on=\"Date\")\n",
    "        self.r_data = self.r_data.drop(columns=\"Date\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    def shift_rdata(self, shift1, shift2):\n",
    "        dfs =[]\n",
    "        arr_all =[]\n",
    "        if shift2==0:\n",
    "            df_s = self.r_data.copy()\n",
    "        else:\n",
    "            df_s = self.r_data.copy()\n",
    "            df_s = df_s.shift(periods=shift2)\n",
    "        arr_all = np.array(df_s)\n",
    "\n",
    "        for i in range(1,shift1):\n",
    "            tp = np.array(df_s.shift(periods=i))\n",
    "            arr_all = np.concatenate((arr_all, tp), axis=1)\n",
    "        df_all = pd.DataFrame(arr_all)\n",
    "        df_all[\"date\"] = self.d_data\n",
    "        df_all = df_all.dropna()\n",
    "        df_all = df_all.reset_index()\n",
    "        df_all = df_all.drop(columns=\"index\")\n",
    "        self.d_data = df_all[\"date\"]\n",
    "        self.r_data = df_all\n",
    "    \n",
    "    \n",
    "    def cutyw_rdata(self):\n",
    "        def trans_to_y_w(d_date):\n",
    "            year = int(d_date.split(\"-\")[0])\n",
    "            d_day = date(year,int(d_date.split(\"-\")[1]), int(d_date.split(\"-\")[2]))- date(year, 1, 1)\n",
    "            d_w = 1+ (d_day.days // 7)\n",
    "            if d_w ==53:\n",
    "                d_w = 52\n",
    "            result =  str(year) + \"_\" + str(d_w)\n",
    "\n",
    "            if d_day.days % 7 ==6:\n",
    "                return result\n",
    "            else:\n",
    "                return np.nan\n",
    "        y_w = []\n",
    "        for i in range(len(self.d_data)):\n",
    "            y_w.append(trans_to_y_w(self.d_data[i]))\n",
    "        self.r_data[\"y_w\"] = y_w\n",
    "        self.r_data_n_drop = self.r_data.copy()\n",
    "        self.r_data = self.r_data.dropna()\n",
    "        self.r_data = self.r_data.reset_index(drop=True)\n",
    "        self.cy_data = self.d_data\n",
    "\n",
    "    \n",
    "    \n",
    "    def join_pbw_r_data(self):\n",
    "        df_join = self.df_pbw.join(self.r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "        df_join = df_join.dropna()\n",
    "        df_join = df_join.reset_index(drop=True)\n",
    "#         df_join = df_join.drop(columns=\"index\")\n",
    "        self.d_data = df_join[\"date\"]\n",
    "        self.r_data = df_join\n",
    "    \n",
    "    \n",
    "    def dummy_market(self,d_t_dummy):\n",
    "        tmp_dum = pd.DataFrame()\n",
    "        for col in d_t_dummy:\n",
    "            tmp_dum[col] = self.r_data[col]\n",
    "            dummy = pd.get_dummies(tmp_dum[col])\n",
    "            self.r_data = pd.concat([self.r_data, dummy], axis=1)\n",
    "        self.r_data = self.r_data.drop(columns=d_t_dummy)\n",
    "        self.x = self.r_data\n",
    "        self.dummy = dummy\n",
    "#         [,\"year\", \"week\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "    \n",
    "    \n",
    "    def drop_x_data(self,drop_c):\n",
    "        self.x_beforedrop = self.x\n",
    "        self.y_raw_price = self.x[\"w_avg\"]\n",
    "        self.x = self.x.drop(columns=drop_c)\n",
    "        self.input_units = self.x.shape[1]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def all_prep(self, shift1, shift2,d_t_dummy):\n",
    "        self.prep_rdata()\n",
    "        self.join_lunar()\n",
    "        self.shift_rdata(shift1, shift2)\n",
    "        self.shift1 = shift1\n",
    "        self.shift2 = shift2\n",
    "        self.cutyw_rdata()\n",
    "        self.join_pbw_r_data()\n",
    "        self.dummy_market(d_t_dummy)\n",
    "        self.extract_xy()\n",
    "        \n",
    "    def all_prep_market_select(self, shift1, shift2,d_t_dummy,market):\n",
    "        self.market_select(market)\n",
    "        self.prep_rdata()\n",
    "        self.join_lunar()\n",
    "        self.shift_rdata(shift1, shift2)\n",
    "        self.shift1 = shift1\n",
    "        self.shift2 = shift2\n",
    "        self.cutyw_rdata()\n",
    "        self.join_pbw_r_data()\n",
    "        self.dummy_market(d_t_dummy)\n",
    "        self.extract_xy()\n",
    "    \n",
    "    def all_prep_nolunar(self, shift1, shift2,d_t_dummy):\n",
    "        self.prep_rdata()\n",
    "#         self.join_lunar()\n",
    "        self.shift_rdata(shift1, shift2)\n",
    "        self.shift1 = shift1\n",
    "        self.shift2 = shift2\n",
    "        self.cutyw_rdata()\n",
    "        self.join_pbw_r_data()\n",
    "        self.dummy_market(d_t_dummy)\n",
    "        self.extract_xy()\n",
    "    \n",
    "    def extract_xy(self):\n",
    "#     y_date = df_join[\"date\"]\n",
    "        self.y_yw = self.r_data[\"y_w\"]\n",
    "        self.y_raw = np.array(self.r_data[\"price_diff\"])\n",
    "        self.y_diff_d = np.array(self.r_data[\"w_avg\"].diff())\n",
    "        \n",
    "    def split_y_to_class(self, input_y, list_y_class=[0]):\n",
    "        y_class = []\n",
    "        for i in range(len(input_y)):\n",
    "            c = 0\n",
    "            y = input_y[i]\n",
    "            for j in range(len(list_y_class)):\n",
    "                if y > list_y_class[j]:\n",
    "                    c = c +1\n",
    "            y_class.append(c)\n",
    "#         print((np.bincount(y_class), list_y_class))\n",
    "        self.output_class = len(np.bincount(y_class))\n",
    "        return np.array(y_class)\n",
    "    \n",
    "    def y_to_class(self, list_y_class=[-0.1,0,0.1]):\n",
    "        y_raw = self.y_raw\n",
    "        self.y_list_class = list_y_class\n",
    "        y_class = []\n",
    "        for i in range(len(y_raw)):\n",
    "            c = 0\n",
    "            y = y_raw[i]\n",
    "            for j in range(len(list_y_class)):\n",
    "                if y > list_y_class[j]:\n",
    "                    c = c +1\n",
    "            y_class.append(c)\n",
    "        self.y_class = np.array(y_class)\n",
    "        self.y_freq = (np.bincount(y_class), list_y_class)\n",
    "        self.output_class =len(np.bincount(y_class))\n",
    "    \n",
    "    \n",
    "    def split_data(self, year,year_s=0):\n",
    "        y_w = self.y_yw\n",
    "        y_raw = self.y_raw\n",
    "        y_year = []\n",
    "        for  i in range(len(y_w)):\n",
    "            y_year.append(int(y_w[i].split(\"_\")[0]))\n",
    "        y_year = np.array(y_year)\n",
    "        self.split_info = np.unique(np.array(y_year), return_counts=True)\n",
    "#         b_train = y_year[:]<=year\n",
    "#         b_test = y_year[:]>year\n",
    "#         delete data before year_s\n",
    "        b_train = (y_year[:]<=year) * (y_year[:]>=year_s)\n",
    "        b_test = (y_year[:]>year) * (y_year[:]>=year_s)\n",
    "        x = np.array(self.x)\n",
    "        y = np.array(self.y_class)\n",
    "        self.split_xy = (x[b_train,:], y[b_train] , x[b_test,:], y[b_test])\n",
    "        self.split_xy_count = (x[b_train,:], y_raw[b_train] , x[b_test,:], y_raw[b_test])\n",
    "    \n",
    "    def model_build(self, dinp=5):\n",
    "        x_train, y_train, x_test, y_test = self.split_xy\n",
    "        model = Sequential()\n",
    "        layer_0 = Dense(units =self.input_units//dinp, input_dim = self.input_units,\n",
    "                        kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "        model.add(layer_0)\n",
    "        model.add(Dropout(0.35))\n",
    "        layer_1 = Dense(units =self.input_units//(dinp*5),\n",
    "                        kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "        model.add(layer_1)\n",
    "        model.add(Dropout(0.35))\n",
    "#         layer_1 = Dense(units =(self.shift1+1),kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "#         model.add(layer_1)\n",
    "#         model.add(Dropout(0.25))\n",
    "        layer_out = Dense(units = self.output_class,kernel_initializer = \"random_normal\", \n",
    "                          activation = \"softmax\")\n",
    "        model.add(layer_out)\n",
    "        #     model.summary()\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "        self.train_model = model\n",
    "\n",
    "    def model_test(self, epochs=10):\n",
    "        x_train, y_train, x_test, y_test = self.split_xy\n",
    "        x_train, x_train_d, y_train, y_train_d = train_test_split(x_train, y_train,  test_size=0.01, shuffle=True)\n",
    "        train_history = self.train_model.fit(x = x_train, y = np_utils.to_categorical(y_train), \n",
    "                                             validation_split = 0.2, epochs =epochs, verbose = 0)\n",
    "        pre = self.train_model.predict_classes(x_test)\n",
    "        acc = round(accuracy_score(y_test, pre)*100,2)\n",
    "        test_result =  (pre , y_test)\n",
    "        in_acc = round(accuracy_score(self.train_model.predict_classes(x_train), y_train)*100,2)\n",
    "        train_result = (self.train_model.predict_classes(x_train), y_train)\n",
    "        return acc,test_result, in_acc,train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = glob.glob(\"./flower_pre_model/04_model/*_15_c*\")\n",
    "m_fn = model_list[0]\n",
    "# for m_fn in model_list:\n",
    "flower = m_fn.split(\"\\\\\")[1].split(\"_\")[0]\n",
    "station = m_fn.split(\"\\\\\")[1].split(\"_\")[1]\n",
    "shift1 =  int(m_fn.split(\"\\\\\")[1].split(\"_\")[2])\n",
    "shift2 = 15\n",
    "y_class_list = [-0.1,0,0.1]\n",
    "fn_weather = glob.glob(\"../result/merge_weather/\"+ station +\"*.csv\")[0]\n",
    "fn_price  = glob.glob(\"../result/flower_price_byweek/\"+ flower + \"*.csv\")[0]\n",
    "\n",
    "fp = fp_pre(fn_weather, fn_price)\n",
    "drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "d_t_dummy = [\"market\",\"week\"]\n",
    "fp.all_prep(shift1,shift2,d_t_dummy)\n",
    "# fp.y_to_class(y_class_list)\n",
    "# fp.drop_x_data(drop_c)\n",
    "# model = load_model(m_fn)\n",
    "\n",
    "# pre  = model.predict_classes(fp.x)\n",
    "# df = pd.DataFrame()\n",
    "# df[\"date\"] = fp.d_data\n",
    "# df[\"price\"]=fp.y_raw_price\n",
    "# # 先給值再覆蓋\n",
    "# df[\"pre_price\"]=fp.y_raw_price\n",
    "# df[\"pre\"]=pre\n",
    "# df[\"ans\"]=fp.y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1907    2019-05-27\n",
       "1908    2019-05-28\n",
       "1909    2019-05-29\n",
       "1910    2019-05-30\n",
       "1911    2019-05-31\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.cy_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = glob.glob(\"./flower_pre_model/04_model/*_15_c*\")\n",
    "# m_fn = model_list[0]\n",
    "for m_fn in model_list:\n",
    "    flower = m_fn.split(\"\\\\\")[1].split(\"_\")[0]\n",
    "    station = m_fn.split(\"\\\\\")[1].split(\"_\")[1]\n",
    "    shift1 =  int(m_fn.split(\"\\\\\")[1].split(\"_\")[2])\n",
    "    shift2 = 15\n",
    "    y_class_list = [-0.1,0,0.1]\n",
    "    fn_weather = glob.glob(\"../result/merge_weather/\"+ station +\"*.csv\")[0]\n",
    "    fn_price  = glob.glob(\"../result/flower_price_byweek/\"+ flower + \"*.csv\")[0]\n",
    "\n",
    "    fp = fp_pre(fn_weather, fn_price)\n",
    "    drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "    d_t_dummy = [\"market\",\"week\"]\n",
    "    fp.all_prep(shift1,shift2,d_t_dummy)\n",
    "    fp.y_to_class(y_class_list)\n",
    "    fp.drop_x_data(drop_c)\n",
    "    model = load_model(m_fn)\n",
    "\n",
    "    pre  = model.predict_classes(fp.x)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"date\"] = fp.d_data\n",
    "    df[\"price\"]=fp.y_raw_price\n",
    "    # 先給值再覆蓋\n",
    "    df[\"pre_price\"]=fp.y_raw_price\n",
    "    df[\"pre\"]=pre\n",
    "    df[\"ans\"]=fp.y_class\n",
    "    m_list = [\"台中\", \"台北\", \"台南\", \"彰化\", \"高雄\"]\n",
    "    for m in m_list:\n",
    "        df[m] = fp.x[m]\n",
    "\n",
    "    price = np.array(df[\"price\"])\n",
    "    pre  = np.array(df[\"pre\"])\n",
    "    pre_price = []\n",
    "\n",
    "    c = [0.9,0.95,1.05,1.1]\n",
    "    for i in range(len(price)):\n",
    "        pre_price.append(price[i]*c[pre[i]])\n",
    "    df[\"pre_price\"]=pre_price\n",
    "    df[\"pre_price\"] = df[\"pre_price\"].shift(periods=1)\n",
    "\n",
    "    arr_m = np.array(df)[:,5:5+5]\n",
    "    market_list = [\"台中\",\"台北\",\"台南\",\"彰化\",\"高雄\"]\n",
    "    m_new = arr_m * market_list\n",
    "    m_done = []\n",
    "    for d in m_new:\n",
    "        m_done.append(\"\".join(d))\n",
    "    df[\"market\"] = m_done\n",
    "    df = df.drop(columns=market_list)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    tags = [\"大跌\",\"小跌\",\"小漲\",\"大漲\"]\n",
    "    pre = np.array(df[\"pre\"]).astype(str)\n",
    "    ans = np.array(df[\"ans\"]).astype(str)\n",
    "    for i in range(len(tags)):\n",
    "        pre[pre==str(i)]=tags[i] \n",
    "        ans[ans==str(i)]=tags[i]\n",
    "    df[\"pre\"]=pre\n",
    "    df[\"ans\"]=ans\n",
    "    # df.head(20)\n",
    "    fn_save = \"../result/predict_result/\" + flower + \".csv\"\n",
    "    df.to_csv(fn_save, encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../result/merge_weather\\C0K490_古坑.csv ../result/flower_price_byweek\\OrientalLily_pbyweek.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre</th>\n",
       "      <th>ans</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>台中</th>\n",
       "      <th>台北</th>\n",
       "      <th>台南</th>\n",
       "      <th>彰化</th>\n",
       "      <th>高雄</th>\n",
       "      <th>pre_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.774</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>184.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135.767</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>141.801</td>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>182.55</td>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>223.601</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>207.095</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>245.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177.126</td>\n",
       "      <td>2015-08-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>217.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>195.512</td>\n",
       "      <td>2015-08-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>159.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173.732</td>\n",
       "      <td>2015-09-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>205.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.58</td>\n",
       "      <td>2015-09-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>156.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>175.452</td>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>176.053</td>\n",
       "      <td>2015-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>192.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>184.789</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>167.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>184.789</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>194.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.807</td>\n",
       "      <td>2015-10-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>194.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>159.064</td>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>149.997</td>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>161.728</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123.642</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>169.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.136</td>\n",
       "      <td>2015-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.1609</td>\n",
       "      <td>2015-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.2226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>110.728</td>\n",
       "      <td>2015-11-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>119.79</td>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>106.43</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.9645</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>113.175</td>\n",
       "      <td>2015-12-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.3896</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>75.7372</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.7432</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.9504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>74.6072</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.4689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>118.484</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>118.484</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>118.484</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.3563</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.3563</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.8207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.3563</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.8207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.3563</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.8207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134.099</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.8207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134.099</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134.099</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134.099</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>154.345</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>154.345</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>169.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>154.345</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>169.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148.79</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>169.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148.79</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>148.79</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155.742</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>163.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155.742</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155.742</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146.643</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146.643</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146.643</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>232.089</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>232.089</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>255.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>232.089</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>255.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>234.096</td>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>255.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>222.131</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>222.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>222.131</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>199.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>222.131</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>199.918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pre ans    price        date 台中 台北 台南 彰化 高雄 pre_price\n",
       "0     0   0  149.774  2015-07-08  0  0  0  1  0   184.336\n",
       "1     1   1  135.767  2015-07-15  0  0  0  1  0   134.796\n",
       "2     2   2  141.801  2015-07-22  0  0  0  1  0   128.978\n",
       "3     3   3   182.55  2015-07-29  0  0  0  1  0   148.891\n",
       "4     3   3  223.601  2015-08-05  0  0  0  1  0   200.805\n",
       "5     2   1  207.095  2015-08-12  0  0  0  1  0   245.961\n",
       "6     0   0  177.126  2015-08-19  0  0  0  1  0    217.45\n",
       "7     2   3  195.512  2015-08-26  0  0  0  1  0   159.413\n",
       "8     0   0  173.732  2015-09-02  0  0  0  1  0   205.287\n",
       "9     0   1   170.58  2015-09-09  0  0  0  1  0   156.359\n",
       "10    3   2  175.452  2015-09-16  0  0  0  1  0   153.522\n",
       "11    1   2  176.053  2015-09-23  0  0  0  1  0   192.997\n",
       "12    2   2  184.789  2015-09-30  0  0  0  1  0    167.25\n",
       "13    2   2  184.789  2015-09-30  0  0  0  1  0   194.028\n",
       "14    0   0  150.807  2015-10-07  0  0  0  1  0   194.028\n",
       "15    1   2  159.064  2015-10-14  0  0  0  1  0   135.726\n",
       "16    2   1  149.997  2015-10-21  0  0  0  1  0   151.111\n",
       "17    2   2  161.728  2015-10-28  0  0  0  1  0   157.497\n",
       "18    0   0  123.642  2015-11-04  0  0  0  1  0   169.815\n",
       "19    0   0  109.136  2015-11-11  0  0  0  1  0   111.278\n",
       "20    0   0  75.1609  2015-11-18  0  0  0  1  0   98.2226\n",
       "21    3   3  110.728  2015-11-25  0  0  0  1  0   67.6448\n",
       "22    1   2   119.79  2015-12-02  0  0  0  1  0   121.801\n",
       "23    2   0   106.43  2015-12-09  0  0  0  1  0   113.801\n",
       "24    0   0  85.9645  2015-12-16  0  0  0  1  0   111.751\n",
       "25    3   3  113.175  2015-12-23  0  0  0  1  0    77.368\n",
       "26    0   0  75.3896  2015-12-30  0  0  0  1  0   124.492\n",
       "27    1   2  75.7372  2016-01-07  0  0  0  1  0   67.8507\n",
       "28    0   0  52.7432  2016-01-14  0  0  0  1  0   71.9504\n",
       "29    3   3  74.6072  2016-01-21  0  0  0  1  0   47.4689\n",
       "..   ..  ..      ...         ... .. .. .. .. ..       ...\n",
       "217   3   3  118.484  2019-03-04  0  0  0  1  0   130.332\n",
       "218   3   3  118.484  2019-03-04  0  0  0  1  0   130.332\n",
       "219   3   3  118.484  2019-03-04  0  0  0  1  0   130.332\n",
       "220   0   0  95.3563  2019-03-11  0  0  0  1  0   130.332\n",
       "221   0   0  95.3563  2019-03-11  0  0  0  1  0   85.8207\n",
       "222   0   0  95.3563  2019-03-11  0  0  0  1  0   85.8207\n",
       "223   0   0  95.3563  2019-03-11  0  0  0  1  0   85.8207\n",
       "224   1   3  134.099  2019-03-18  0  0  0  1  0   85.8207\n",
       "225   1   3  134.099  2019-03-18  0  0  0  1  0   127.394\n",
       "226   1   3  134.099  2019-03-18  0  0  0  1  0   127.394\n",
       "227   1   3  134.099  2019-03-18  0  0  0  1  0   127.394\n",
       "228   3   3  154.345  2019-03-25  0  0  0  1  0   127.394\n",
       "229   3   3  154.345  2019-03-25  0  0  0  1  0   169.779\n",
       "230   3   3  154.345  2019-03-25  0  0  0  1  0   169.779\n",
       "231   0   1   148.79  2019-04-01  0  0  0  1  0   169.779\n",
       "232   0   1   148.79  2019-04-01  0  0  0  1  0   133.911\n",
       "233   3   1   148.79  2019-04-01  0  0  0  1  0   133.911\n",
       "234   0   2  155.742  2019-04-08  0  0  0  1  0   163.669\n",
       "235   0   2  155.742  2019-04-08  0  0  0  1  0   140.167\n",
       "236   0   2  155.742  2019-04-08  0  0  0  1  0   140.167\n",
       "237   0   1  146.643  2019-04-15  0  0  0  1  0   140.167\n",
       "238   0   1  146.643  2019-04-15  0  0  0  1  0   131.978\n",
       "239   0   1  146.643  2019-04-15  0  0  0  1  0   131.978\n",
       "240   3   3  232.089  2019-04-22  0  0  0  1  0   131.978\n",
       "241   3   3  232.089  2019-04-22  0  0  0  1  0   255.298\n",
       "242   3   3  232.089  2019-04-22  0  0  0  1  0   255.298\n",
       "243   1   2  234.096  2019-04-29  0  0  0  1  0   255.298\n",
       "244   0   1  222.131  2019-05-06  0  0  0  1  0   222.391\n",
       "245   0   1  222.131  2019-05-06  0  0  0  1  0   199.918\n",
       "246   0   1  222.131  2019-05-06  0  0  0  1  0   199.918\n",
       "\n",
       "[247 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_info = {}\n",
    "# w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "# p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "# select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "# st, flower = select_t[3]\n",
    "# fn_weather = w_list[st]\n",
    "# fn_price = p_list[flower]\n",
    "# print(fn_weather, fn_price)\n",
    "# fp = fp_pre(fn_weather, fn_price)\n",
    "# drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# d_t_dummy = [\"market\",\"week\"]\n",
    "# # fp.all_prep(12,1,d_t_dummy)\n",
    "# fp.all_prep(11,1,d_t_dummy)\n",
    "# fp.y_to_class([-0.1,0,0.1])\n",
    "# # fp.y_to_class([0])\n",
    "# fp.drop_x_data(drop_c)\n",
    "# fp.x.shape,fp.y_yw.shape,fp.y_class.shape\n",
    "# model = load_model(\"./flower_pre_model/04_model/OrientalLily_C0K490_11_1_c4.h5\")\n",
    "# # model = load_model(\"./flower_pre_model/01_model/OrientalLily_C0K490_12_1.h5\")\n",
    "# # x_train, y_train, x_test, y_test = fp.split_xy\n",
    "# pre  = model.predict_classes(fp.x)\n",
    "# df = pd.DataFrame()\n",
    "# df[\"pre\"]=pre\n",
    "# # df[\"y_yw\"]=fp.y_yw\n",
    "# df[\"ans\"]=fp.y_class\n",
    "# df[\"price\"]=fp.y_raw_price\n",
    "# df[\"date\"] = fp.d_data\n",
    "# m_list = [\"台中\", \"台北\", \"台南\", \"彰化\", \"高雄\"]\n",
    "# for m in m_list:\n",
    "#     df[m] = fp.x[m]\n",
    "# df.head()\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# df[\"pre\"]=pre\n",
    "# # df[\"y_yw\"]=fp.y_yw\n",
    "# df[\"ans\"]=fp.y_class\n",
    "# df[\"price\"]=fp.y_raw_price\n",
    "# df[\"date\"] = fp.d_data\n",
    "# m_list = [\"台中\", \"台北\", \"台南\", \"彰化\", \"高雄\"]\n",
    "# for m in m_list:\n",
    "#     df[m] = fp.x[m]\n",
    "# # df.to_csv(\"result_to_plot.csv\", index=False)\n",
    "# # df.to_csv(\"test0529.csv\",index=False)\n",
    "# price = np.array(df[\"price\"])\n",
    "# pre  = np.array(df[\"pre\"])\n",
    "# pre_price = []\n",
    "\n",
    "# c = [0.9,0.95,1.05,1.1]\n",
    "# for i in range(len(price)):\n",
    "#     pre_price.append(price[i]*c[pre[i]])\n",
    "# df[\"pre_price\"]=pre_price\n",
    "# df[\"pre_price\"] = df[\"pre_price\"].shift(periods=1)\n",
    "# # df.head(5)\n",
    "# arr = np.array(df)\n",
    "# arr = arr[arr[:,7]==1]\n",
    "# # arr = arr[-80:]\n",
    "# df_m_s= pd.DataFrame(arr,columns=df.columns.to_list())\n",
    "# df_m_s\n",
    "# # df_new = df_m_s[[\"price\", \"pre_price\"]]\n",
    "# # mse = mean_squared_error(df_new[\"price\"], df_new[\"pre_price\"])\n",
    "\n",
    "# # print(best_mse, best_t)\n",
    "# # arr = arr[:,0:4]\n",
    "# # plt.plot(range(len(df_new)),df_new[\"price\"])\n",
    "# # plt.plot(range(len(df_new)),df_new[\"pre_price\"])\n",
    "# # df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m = pd.DataFrame()\n",
    "# m_list = [\"台中\", \"台北\", \"台南\", \"彰化\", \"高雄\"]\n",
    "# for m in m_list:\n",
    "#     df[m] = fp.x[m]\n",
    "# df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(20)\n",
    "# # m = m_list[0]\n",
    "# arr = np.array(df)\n",
    "# # select m \n",
    "# arr = arr[arr[:,5]==1]\n",
    "# arr = arr[:,0:4]\n",
    "# arr[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # arr = np.array(df)\n",
    "# green = arr[arr[:,0]==0]\n",
    "# red = arr[arr[:,0]==1]\n",
    "# plt.plot(green[:,3],green[:,2])\n",
    "# plt.plot(red[:,3],red[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_info = {}\n",
    "# w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "# p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "# select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "# st, flower = select_t[3]\n",
    "# fn_weather = w_list[st]\n",
    "# fn_price = p_list[flower]\n",
    "# fp = fp_pre(fn_weather, fn_price)\n",
    "# model_info[\"flower\"]= fp.flower_name\n",
    "# model_info[\"station\"]= fp.station_name\n",
    "# drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# d_t_dummy = [\"market\"]\n",
    "# fp.all_prep(1,1,d_t_dummy)\n",
    "# fp.dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "# p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "# # st = 0\n",
    "# records = pd.DataFrame()\n",
    "# for st in range(4):\n",
    "#     fn_weather = w_list[st]\n",
    "#     st_n  = fn_weather.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "#     fn_price = p_list[0]\n",
    "#     print(fn_weather, fn_price)\n",
    "#     fp = fp_pre(fn_weather, fn_price)\n",
    "#     fp.prep_rdata()\n",
    "#     records[st_n] = fp.recordz\n",
    "# records\n",
    "# records.to_csv(\"./flower_pre_model/weather_trans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main_model_run(select,year_split,shift1, shift2, list_split_y):\n",
    "# #     class_y_diff =[0]\n",
    "#     model_info = {}\n",
    "#     w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "#     p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "#     select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "#     st, flower = select_t[select]\n",
    "#     fn_weather = w_list[st]\n",
    "#     fn_price = p_list[flower]\n",
    "#     fp = fp_pre(fn_weather, fn_price)\n",
    "#     model_info[\"flower\"]= fp.flower_name\n",
    "#     model_info[\"station\"]= fp.station_name\n",
    "#     drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "#     d_t_dummy = [\"market\", \"week\"]\n",
    "#     fp.all_prep(shift1, shift2,d_t_dummy)\n",
    "# #     fp.y_to_class(list_split_y)\n",
    "#     fp.y_to_class(list_split_y)\n",
    "#     fp.drop_x_data(drop_c)\n",
    "    \n",
    "#     fp.split_data(year_split)\n",
    "#     model_info[\"weather_trans\"] = fp.recordz\n",
    "#     model_info[\"shift\"] = (shift1, shift2)\n",
    "#     dinp = 5\n",
    "#     acc = []\n",
    "#     epo_cf = []\n",
    "#     acc_max = 0\n",
    "#     epochs = 3\n",
    "#     epochs_try =20\n",
    "#     plot_x = []\n",
    "#     fp.model_build(dinp)\n",
    "#     test_acc = []\n",
    "#     train_acc = []\n",
    "#     #         print(epochs, end=\"\\t\")\n",
    "#     for i in range(epochs_try):\n",
    "#         t_acc , test_result, in_acc,train_result= fp.model_test(epochs)\n",
    "#         acc.append(t_acc)\n",
    "#         if t_acc>acc_max and in_acc>50:\n",
    "#             acc_max = t_acc\n",
    "#             best_test = test_result\n",
    "#             in_acc_max  = in_acc\n",
    "#             best_train = train_result\n",
    "#             best_epochs = epochs*(i+1)\n",
    "#             best_mode = fp.train_model\n",
    "#         test_acc.append(t_acc)\n",
    "#         train_acc.append(in_acc)\n",
    "#     model_info[\"acc_info\"] = [acc_max, in_acc_max, best_epochs]\n",
    "# #     model_info.append(best_mode)\n",
    "#     return model_info, best_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_model_data =[]\n",
    "# save_path = \"./flower_pre_model/04_model/\"\n",
    "# select = 0\n",
    "# year_split = 2018\n",
    "# shift1 = 7\n",
    "# shift2 = 1\n",
    "\n",
    "# list_split_y = [-0.1,0,0.1]\n",
    "# for shift2 in [1,8,15]: # [1,8,15]:\n",
    "#     for select in range(5): \n",
    "#         best_test_acc = 0 \n",
    "#         for shift1 in range(7,16,2):\n",
    "#             records , best_model= main_model_run(select,year_split,shift1, shift2, list_split_y)\n",
    "#             model_fn = save_path + \"_\".join((records[\"flower\"], records[\"station\"], str(records[\"shift\"][0]),\n",
    "#                                              str(records[\"shift\"][1]))) + \"_c4.h5\"\n",
    "#             model_data  = [records[\"flower\"], records[\"station\"], str(records[\"shift\"][0]),\n",
    "#                            str(records[\"shift\"][1]), records['acc_info'][0], records['acc_info'][1]]\n",
    "#             if best_test_acc< records['acc_info'][0]:\n",
    "#                 best_test_acc = records['acc_info'][0]\n",
    "#                 best_model_save = best_model\n",
    "#                 best_model_fn = model_fn\n",
    "#             all_model_data.append(model_data)\n",
    "            \n",
    "#         best_model_save.save(best_model_fn)\n",
    "# pd.DataFrame(all_model_data, columns=[\"flower\", \"station\", \"shift1\", \"shift2\", \"test_acc\", \"train_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # records\n",
    "# df = pd.DataFrame(all_model_data, columns=[\"flower\", \"station\", \"shift1\", \"shift2\", \"test_acc\", \"train_acc\"])\n",
    "# df.to_csv(\"./flower_pre_model/04_model/result.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(all_model_data, columns=[\"flower\", \"station\", \"shift1\", \"shift2\", \"test_acc\", \"train_acc\"])\n",
    "# g = df.groupby([\"flower\",\"shift2\"])\n",
    "# best_data = []\n",
    "# for flower in [\"Anthurium\", \"Eustoma\", \"Chrysanthemum\",\"OrientalLily\",\"Rose\"]:\n",
    "#     for sh2 in [\"1\",\"8\",\"15\"]:\n",
    "#         df_t = g.get_group((flower,sh2))\n",
    "#         best_data.append(list(df_t.loc[df_t['test_acc'].idxmax()]))\n",
    "# df_b = pd.DataFrame(best_data, columns=['flower', 'station', 'shift1', 'shift2', 'test_acc', 'train_acc'])\n",
    "# df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_b.to_csv(\"./flower_pre_model/04_model/result_best.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select = 0\n",
    "# year_split = 2018\n",
    "# shift1 = 7\n",
    "# shift2 = 1\n",
    "# list_split_y = [0]\n",
    "# model_info = []\n",
    "# w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "# p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "# select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "# st, flower = select_t[select]\n",
    "# fn_weather = w_list[st]\n",
    "# fn_price = p_list[flower]\n",
    "# fp = fp_pre(fn_weather, fn_price)\n",
    "# model_info.append(fp.flower_name)\n",
    "# drop_c = [\"year\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# d_t_dummy = [\"market\", \"week\"]\n",
    "# fp.all_prep(shift1, shift2,d_t_dummy)\n",
    "# fp.y_to_class(list_split_y)\n",
    "# fp.drop_x_data(drop_c)\n",
    "# fp.split_data(year_split, year_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_model_run(select,year_split,shift1, shift2, class_y_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 花名 測站名稱 shift (參數,預測週(1,8,15), 準確率範圍)\n",
    "# Anthurium 467480     shift:(14,1,55~63%), (27,8,46~65%) (19,15,55~72%)\n",
    "# Chrysanthemum C0F9L0 shift:(19,1,51~58%), (16,8,40~59%) (16,15,33~50%)\n",
    "# Eustoma C0F9L0       shift:(3,1,67~73%) (16,8,49~57%) (12,15,51~63%)  epochs [10,]\n",
    "# OrientalLily C0X060  shift:(17,1,77~79%) (22,8,66~75%) (14,15,43~64%) epochs [ , 12, ]\n",
    "# Rose C0X060          shift:(7,1,47~64%) (18,8,42~64%) (18,15,55~69%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
