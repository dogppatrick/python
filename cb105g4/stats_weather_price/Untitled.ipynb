{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import date, time, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "opt_week = [1, 2]\n",
    "opt_flower = ['Anthurium', 'Chrysanthemum', 'OrientalLily', 'Eustoma', 'Rose']\n",
    "opt_market = [\"台北\", \"台中\", \"台南\", \"高雄\", \"彰化\"]\n",
    "station_info =  (opt_week[0], opt_flower[0], opt_market[0])\n",
    "\n",
    "pre_week, pre_flower, pre_market = station_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_test0519\\C0F9L0_后里_Anthurium_shift0_epo28_80.h5\n"
     ]
    }
   ],
   "source": [
    "model_list = glob.glob(\"./model_test0519//*\"+pre_flower + \"*\")\n",
    "for m in model_list:\n",
    "    keyw = \"shift\" + str((pre_week-1)*7)\n",
    "    if keyw in models:\n",
    "        model_fn = models\n",
    "\n",
    "station_name  = model_fn.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "\n",
    "\n",
    "\n",
    "print(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift1 = int(model_fn.split(\"\\\\\")[-1].split(\"_\")[3].replace(\"shift\",\"\"))\n",
    "shift1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 0.7882\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.7367\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6880\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6438\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6021\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.5630\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.5278\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4960\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4651\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4381\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4114\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.3888\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.3669\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.3476\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.3301\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.3141\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2999\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2861\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2736\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2617\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2510\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2417\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2333\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2261\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2198\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2141\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2091\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2046\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2005\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1964\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.1928\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1891\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1842\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1781\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1704\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1620\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1522\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1429\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1336\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1241\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1158\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1077\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0999\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0928\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0859\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0798\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0743\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0695\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0650\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0615\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0580\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0549\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0521\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0499\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0473\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0455\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0436\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0421\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0409\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0398\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0391\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0384\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0380\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0375\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0371\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0368\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0365\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0361\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0359\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0356\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0355\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0352\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0350\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0348\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0347\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0345\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0344\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0343\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0341\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0339\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0338\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0336\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0335\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0333\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0332\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0331\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0329\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0328\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0327\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0325\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0324\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0323\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0322\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0321\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0320\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0319\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0317\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0315\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0313\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158c0b28cc0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of training a final regression model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=1)\n",
    "scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n",
    "scalarX.fit(X)\n",
    "scalarY.fit(y.reshape(100,1))\n",
    "X = scalarX.transform(X)\n",
    "y = scalarY.transform(y.reshape(100,1))\n",
    "# define and fit the final model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "# example of training a final regression model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=1)\n",
    "scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n",
    "scalarX.fit(X)\n",
    "scalarY.fit(y.reshape(100,1))\n",
    "X = scalarX.transform(X)\n",
    "y = scalarY.transform(y.reshape(100,1))\n",
    "# define and fit the final model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53688946, 0.6063968 ],\n",
       "       [0.08928015, 0.49554592],\n",
       "       [0.44371796, 0.35008139],\n",
       "       [0.24288159, 0.50350501],\n",
       "       [0.33476199, 0.37985168],\n",
       "       [0.17721717, 0.41476488],\n",
       "       [0.        , 0.35288567],\n",
       "       [0.98123584, 0.4671121 ],\n",
       "       [0.41766512, 0.09435455],\n",
       "       [0.77449219, 0.1726652 ],\n",
       "       [0.6529148 , 0.43321075],\n",
       "       [0.54354762, 0.52013594],\n",
       "       [0.76720782, 0.85781503],\n",
       "       [0.66060983, 0.4413286 ],\n",
       "       [0.47301803, 1.        ],\n",
       "       [0.1165076 , 0.92302729],\n",
       "       [0.359096  , 0.41797454],\n",
       "       [0.64593103, 0.14315543],\n",
       "       [0.34084467, 0.61649633],\n",
       "       [0.39323832, 0.39840682],\n",
       "       [0.57301521, 0.64845363],\n",
       "       [0.02884127, 0.6208843 ],\n",
       "       [0.45762002, 0.57863058],\n",
       "       [0.61528573, 0.67925004],\n",
       "       [0.55660766, 0.54429544],\n",
       "       [0.38861495, 0.33802849],\n",
       "       [0.48901426, 0.53648613],\n",
       "       [0.336876  , 0.38427621],\n",
       "       [0.45059935, 0.49202026],\n",
       "       [0.32046639, 0.59242045],\n",
       "       [0.32434607, 0.39556999],\n",
       "       [0.53387057, 0.36289369],\n",
       "       [0.37887907, 0.62896588],\n",
       "       [0.61553479, 0.46611945],\n",
       "       [0.50105475, 0.3924798 ],\n",
       "       [0.27921838, 0.5422689 ],\n",
       "       [0.79175466, 0.32164942],\n",
       "       [0.36211531, 0.82137278],\n",
       "       [0.47285888, 0.496322  ],\n",
       "       [0.89300204, 0.25324799],\n",
       "       [0.51099489, 0.48757341],\n",
       "       [0.22466085, 0.92185904],\n",
       "       [0.71361172, 0.15017502],\n",
       "       [0.59500342, 0.11054048],\n",
       "       [0.29466096, 0.30317302],\n",
       "       [0.61774833, 0.56090484],\n",
       "       [0.45122835, 0.16311297],\n",
       "       [0.7163863 , 0.46007237],\n",
       "       [0.64156434, 0.36251306],\n",
       "       [0.28883584, 0.68206601],\n",
       "       [0.9524261 , 0.71398044],\n",
       "       [0.85564925, 0.68157812],\n",
       "       [0.50514383, 0.52421   ],\n",
       "       [0.39445118, 0.79390858],\n",
       "       [0.70595874, 0.35377771],\n",
       "       [0.66035514, 0.45098087],\n",
       "       [0.67449423, 0.47659139],\n",
       "       [0.52407375, 0.27055461],\n",
       "       [0.34394092, 0.26692364],\n",
       "       [0.77119483, 0.45135985],\n",
       "       [0.48337688, 0.37289992],\n",
       "       [0.72186423, 0.27610129],\n",
       "       [0.69168655, 0.47604427],\n",
       "       [0.39190363, 0.60433262],\n",
       "       [0.46465053, 0.72713528],\n",
       "       [0.55256324, 0.46879558],\n",
       "       [0.59994786, 0.79466215],\n",
       "       [0.46263113, 0.48030855],\n",
       "       [0.31109211, 0.30569845],\n",
       "       [0.28404823, 0.42755581],\n",
       "       [0.39614657, 0.38234017],\n",
       "       [0.63553616, 0.6291334 ],\n",
       "       [0.50479967, 0.38105219],\n",
       "       [0.68736638, 0.8019921 ],\n",
       "       [0.60850555, 0.27068772],\n",
       "       [0.65373871, 0.37596261],\n",
       "       [0.72827192, 0.61486005],\n",
       "       [0.53624676, 0.34519426],\n",
       "       [0.68917682, 0.62167734],\n",
       "       [0.44097031, 0.26590044],\n",
       "       [0.60675925, 0.6881233 ],\n",
       "       [0.56687531, 0.69691869],\n",
       "       [0.6778437 , 0.28223762],\n",
       "       [0.46231704, 0.54052563],\n",
       "       [0.56346237, 0.17396637],\n",
       "       [0.47784742, 0.43354252],\n",
       "       [0.71832758, 0.4886956 ],\n",
       "       [0.5775333 , 0.16885991],\n",
       "       [0.59465471, 0.13346604],\n",
       "       [0.17469306, 0.57383839],\n",
       "       [0.57890103, 0.55188628],\n",
       "       [0.80662287, 0.53830395],\n",
       "       [0.08107137, 0.75692134],\n",
       "       [0.38899029, 0.43517003],\n",
       "       [0.79789087, 0.25159748],\n",
       "       [0.75279474, 0.60846931],\n",
       "       [0.79427668, 0.        ],\n",
       "       [1.        , 0.66042028],\n",
       "       [0.51046284, 0.53496021],\n",
       "       [0.6552436 , 0.51557568]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
