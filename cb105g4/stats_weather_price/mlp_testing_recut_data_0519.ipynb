{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../result/merge_weather\\C0F9L0_后里.csv ../result/flower_price_byweek\\Anthurium_pbyweek.csv\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import date, time, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "\n",
    "w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "st, flower = select_t[0]\n",
    "fn_weather = w_list[st]\n",
    "fn_price = p_list[flower]\n",
    "\n",
    "print(fn_weather, fn_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_data = pd.read_csv(fn_weather, encoding=\"utf-8\")\n",
    "lc_d = pd.read_csv(\"../lunar_celeb_date.csv\", encoding=\"utf-8\")\n",
    "col_fix =  ['T.Max', 'T.Min', 'Precp','Temperature', 'RH', 'StnPres', 'WS', 'WSGust']\n",
    "r_data = r_data.join(lc_d.set_index(\"date\"), on=\"Date\")\n",
    "# rm \"/\"\n",
    "for col in col_fix:\n",
    "    old = r_data[col]\n",
    "    new = []\n",
    "    for i in range(len(old)):\n",
    "        try:\n",
    "            new.append(float(old[i]))\n",
    "            tmp = float(old[i])\n",
    "        except ValueError:\n",
    "            new.append(tmp)\n",
    "    r_data[col] = new\n",
    "d_tmp = r_data['T.Max'] - r_data['T.Min']\n",
    "r_data[\"d_tmp\"]= d_tmp\n",
    "\n",
    "# extract_date\n",
    "d_data = r_data[\"Date\"]\n",
    "drop_c =[\"Date\",'T.Max', 'T.Min']\n",
    "r_data = r_data.drop(columns=drop_c)\n",
    "\n",
    "def to_zscore2(df):\n",
    "    col_x = df.columns.to_list()\n",
    "    mean = df.mean(axis=0)\n",
    "    std = df.std(axis=0)\n",
    "    for i in range(len(col_x)):\n",
    "        df[col_x[i]]=(df[col_x[i]]-mean[i])/std[i]\n",
    "    return  df , (mean, std)\n",
    "\n",
    "r_data, recordz = to_zscore2(r_data)\n",
    "\n",
    "# r_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(r_data.shape)\n",
    "# print(d_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift1=28\n",
    "shift2=1\n",
    "\n",
    "dfs =[]\n",
    "arr_all =[]\n",
    "if shift2==0:\n",
    "    df_s = r_data.copy()\n",
    "else:\n",
    "    df_s = r_data.copy()\n",
    "    df_s = df_s.shift(periods=shift2)\n",
    "#     d_data = np.array(pd.DataFrame(d_data).shift(periods=shift2))\n",
    "#     add shift base\n",
    "arr_all = np.array(df_s)\n",
    "\n",
    "for i in range(1,shift1):\n",
    "    tp = np.array(df_s.shift(periods=i))\n",
    "    arr_all = np.concatenate((arr_all, tp), axis=1)\n",
    "df_all = pd.DataFrame(arr_all)\n",
    "df_all[\"date\"] = d_data\n",
    "df_all = df_all.dropna()\n",
    "df_all = df_all.reset_index()\n",
    "df_all = df_all.drop(columns=\"index\")\n",
    "\n",
    "# r_data = df_all\n",
    "\n",
    "# df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_data = df_all\n",
    "\n",
    "d_data = r_data[\"date\"]\n",
    "\n",
    "def trans_to_y_w(d_date):\n",
    "    year = int(d_date.split(\"-\")[0])\n",
    "    d_day = date(year,int(d_date.split(\"-\")[1]), int(d_date.split(\"-\")[2]))- date(year, 1, 1)\n",
    "    d_w = 1+ (d_day.days // 7)\n",
    "    if d_w ==53:\n",
    "        d_w = 52\n",
    "    result =  str(year) + \"_\" + str(d_w)\n",
    "\n",
    "    if d_day.days % 7 ==6:\n",
    "        return result\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "d_new = []\n",
    "for i in range(len(d_data)):\n",
    "    d_new.append(trans_to_y_w(d_data[i]))\n",
    "r_data[\"y_w\"] = d_new\n",
    "df_all = df_all.dropna()\n",
    "df_all = df_all.reset_index()\n",
    "df_all = df_all.drop(columns=\"index\")\n",
    "# r_data\n",
    "# d_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pbw = pd.read_csv(fn_price, encoding=\"utf-8\")\n",
    "# join x and y\n",
    "df_join = df_pbw.join(r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "df_join = df_join.dropna()\n",
    "df_join = df_join.reset_index()\n",
    "df_join = df_join.drop(columns=\"index\")\n",
    "# extract y info\n",
    "y_date = df_join[\"date\"]\n",
    "y_yw = df_join[\"y_w\"]\n",
    "y_raw = np.array(df_join[\"price_diff\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7874, 621)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d_t_dummy = [\"market\"]\n",
    "tmp_dum = pd.DataFrame()\n",
    "for col in d_t_dummy:\n",
    "    tmp_dum[col] = df_join[col]\n",
    "    dummy = pd.get_dummies(tmp_dum[col])\n",
    "    df_join = pd.concat([df_join, dummy], axis=1)\n",
    "drop_c = [\"market\",\"year\", \"week\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# x finished\n",
    "x = np.array(df_join.drop(columns=drop_c))\n",
    "# x\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_price_diff describe:\n",
      "       y_price_diff\n",
      "count   7874.000000\n",
      "mean       0.009691\n",
      "std        0.155143\n",
      "min       -0.410906\n",
      "25%       -0.092490\n",
      "50%       -0.005299\n",
      "75%        0.093753\n",
      "max        0.791508\n",
      "======\n",
      "freq: [ 511 1285 2236 1966  979  897]\n",
      "(7874, 621) 7874\n"
     ]
    }
   ],
   "source": [
    "# modify y\n",
    "# y_raw = np.array(df_join[\"price_diff\"])\n",
    "print(\"y_price_diff describe:\")\n",
    "print(pd.DataFrame(y_raw, columns=[\"y_price_diff\"]).describe())\n",
    "print(\"======\")\n",
    "def y_to_class(v):\n",
    "    t = 0\n",
    "    y_class_range = [-0.2,-0.1,0,0.1,0.2]\n",
    "#     for q in range(1,12):\n",
    "#         y_class_range.append(round((q*0.1-0.6),4))\n",
    "\n",
    "    for i in range(len(y_class_range)):\n",
    "        if (v >= y_class_range[i]):\n",
    "            t = i+1\n",
    "    return int(t)\n",
    "\n",
    "y_class = []\n",
    "\n",
    "for i in range(len(y_raw)):\n",
    "    y_class.append(y_to_class(y_raw[i]))\n",
    "print(\"freq:\",np.bincount(y_class))\n",
    "\n",
    "y = np.array(y_class)\n",
    "input_d = x.shape[1]\n",
    "print(x.shape,len(y))\n",
    "# x y ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2014 2015 2016 2017 2018]\n",
      "[1488 1612 1581 1612 1581]\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "# y_date\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "y_year = []\n",
    "for i in range(len(y_yw)):\n",
    "    y_year.append(int(y_yw[i].split(\"_\")[0]))\n",
    "y_year = np.array(y_year)\n",
    "years, count = np.unique(np.array(y_year), return_counts=True)\n",
    "print(years)\n",
    "print(count)\n",
    "\n",
    "train = y_year[:]<=2016\n",
    "test = y_year[:]>2016\n",
    "\n",
    "x_train, y_train = x[train,:], y[train]\n",
    "x_test, y_test = x[test,:], y[test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_class_count = len(np.bincount(y))\n",
    "# shifts = 28\n",
    "# xy_data = (x_train, y_train, x_test, y_test)\n",
    "# def model_build(xy_data, input_d, shifts, epochs=60):\n",
    "#     x_train, y_train, x_test, y_test = xy_data\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     layer_0 = Dense(units =input_d//4, input_dim = input_d,\n",
    "#                     kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "#     model.add(layer_0)\n",
    "#     model.add(Dropout(0.25))\n",
    "#     layer_1 = Dense(units =shifts,kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "#     model.add(layer_1)\n",
    "#     model.add(Dropout(0.25))\n",
    "#     layer_out = Dense(units = out_class_count,kernel_initializer = \"random_normal\", \n",
    "#                       activation = \"softmax\")\n",
    "#     model.add(layer_out)\n",
    "#     #     model.summary()\n",
    "#     model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "#     train_history = model.fit(x = x_train, y = np_utils.to_categorical(y_train), \n",
    "#                               validation_split = 0.1, epochs =epochs, verbose = 2)\n",
    "    \n",
    "#     #     model_test\n",
    "#     pre = model.predict_classes(x_test)\n",
    "#     acc = round(accuracy_score(y_test, pre)*100,2)\n",
    "    \n",
    "#     return acc, model, train_history\n",
    "\n",
    "# acc_cf = 0\n",
    "\n",
    "# for epochs in range(5,80,5):\n",
    "#     print(\"epochs:\", epochs)\n",
    "#     acc, model ,train_history= model_build(xy_data, input_d, shifts, epochs=60)\n",
    "#     print(train_history)\n",
    "#     print(acc)\n",
    "#     if acc > acc_cf:\n",
    "#         acc_cf = acc\n",
    "#         bestmodel = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.33\n",
      "23.27\n",
      "24.68\n",
      "23.74\n",
      "21.83\n",
      "25.84\n",
      "26.34\n",
      "23.74\n",
      "21.74\n",
      "24.27\n"
     ]
    }
   ],
   "source": [
    "out_class_count = len(np.bincount(y))\n",
    "# shifts = 28\n",
    "result_table = []\n",
    "max_res = []\n",
    "acc_cf =0\n",
    "dinp, epochs = (6,6)\n",
    "for i in range(10):\n",
    "    #     epochs = 80\n",
    "    # xy_data = (x_train, y_train, x_test, y_test)\n",
    "    # x_train, y_train, x_test, y_test = xy_data\n",
    "    model = Sequential()\n",
    "    layer_0 = Dense(units =input_d//dinp, input_dim = input_d,\n",
    "                    kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "    model.add(layer_0)\n",
    "    model.add(Dropout(0.25))\n",
    "    # layer_1 = Dense(units =shift1,kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "    # model.add(layer_1)\n",
    "    # model.add(Dropout(0.25))\n",
    "    layer_out = Dense(units = out_class_count,kernel_initializer = \"random_normal\", \n",
    "                      activation = \"softmax\")\n",
    "    model.add(layer_out)\n",
    "    #     model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    train_history = model.fit(x = x_train, y = np_utils.to_categorical(y_train), \n",
    "                              validation_split = 0.2, epochs =epochs, verbose = 0)\n",
    "    #     plt.plot(train_history.history[\"loss\"])\n",
    "    #     plt.plot(train_history.history[\"val_loss\"])\n",
    "    #     plt.title(\"Loss Graph\")\n",
    "    #     plt.legend(['loss', 'val_loss'], loc=\"upper left\")\n",
    "\n",
    "    #     model_test\n",
    "    pre = model.predict_classes(x_test)\n",
    "    acc = round(accuracy_score(y_test, pre)*100,2)\n",
    "    #         if acc > acc_cf:\n",
    "    #             max_res = dinp, epochs, acc\n",
    "    #             acc_cf = acc\n",
    "    #         result_table.append([dinp, epochs, acc])\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc\n",
    "# pd.DataFrame(result_table)\n",
    "# max_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>126</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>265</td>\n",
       "      <td>168</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>503</td>\n",
       "      <td>180</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>379</td>\n",
       "      <td>178</td>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>141</td>\n",
       "      <td>202</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2    3   4   5\n",
       "0  0  47  126   90   0   1\n",
       "1  6  53  265  168  31   8\n",
       "2  1  75  503  180  52  24\n",
       "3  8  47  379  178  77  61\n",
       "4  0  18  141  202  15  43\n",
       "5  0   4  172  128  64  26"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pre = model.predict_classes(x_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, pre))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
