{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../result/merge_weather\\C0G650_員林.csv ../result/flower_price_byweek\\OrientalLily_pbyweek.csv\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import date, time, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "\n",
    "w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "st, flower = select_t[3]\n",
    "fn_weather = w_list[st]\n",
    "fn_price = p_list[flower]\n",
    "\n",
    "print(fn_weather, fn_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Precp</th>\n",
       "      <th>RH</th>\n",
       "      <th>StnPres</th>\n",
       "      <th>WS</th>\n",
       "      <th>WSGust</th>\n",
       "      <th>d_tmp</th>\n",
       "      <th>g_marry</th>\n",
       "      <th>g_pray</th>\n",
       "      <th>g_funeral</th>\n",
       "      <th>...</th>\n",
       "      <th>b_pray</th>\n",
       "      <th>b_funeral</th>\n",
       "      <th>b_business</th>\n",
       "      <th>month</th>\n",
       "      <th>spring</th>\n",
       "      <th>valetine_west</th>\n",
       "      <th>mother</th>\n",
       "      <th>graduation</th>\n",
       "      <th>ghost</th>\n",
       "      <th>valetine_east</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.405393</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-0.342541</td>\n",
       "      <td>0.782879</td>\n",
       "      <td>-1.540053</td>\n",
       "      <td>-1.307154</td>\n",
       "      <td>2.639062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.965367</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-0.586510</td>\n",
       "      <td>0.512573</td>\n",
       "      <td>-0.997534</td>\n",
       "      <td>-1.398144</td>\n",
       "      <td>2.521348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.585346</td>\n",
       "      <td>-0.179558</td>\n",
       "      <td>-0.220556</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>-0.726275</td>\n",
       "      <td>-1.170668</td>\n",
       "      <td>0.520201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.165379</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-1.074449</td>\n",
       "      <td>0.343632</td>\n",
       "      <td>-0.726275</td>\n",
       "      <td>-1.170668</td>\n",
       "      <td>0.912583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.565402</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-1.562388</td>\n",
       "      <td>0.664620</td>\n",
       "      <td>-0.997534</td>\n",
       "      <td>-1.352649</td>\n",
       "      <td>1.422679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.625405</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-0.342541</td>\n",
       "      <td>0.749091</td>\n",
       "      <td>-0.726275</td>\n",
       "      <td>-1.307154</td>\n",
       "      <td>0.912583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.165379</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-0.220556</td>\n",
       "      <td>0.613938</td>\n",
       "      <td>-0.997534</td>\n",
       "      <td>-1.079678</td>\n",
       "      <td>2.011252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.045372</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-0.342541</td>\n",
       "      <td>0.647726</td>\n",
       "      <td>-0.455016</td>\n",
       "      <td>-1.079678</td>\n",
       "      <td>1.618870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.705410</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-1.074449</td>\n",
       "      <td>1.340385</td>\n",
       "      <td>0.901281</td>\n",
       "      <td>-0.351756</td>\n",
       "      <td>-0.892373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.525400</td>\n",
       "      <td>-0.246367</td>\n",
       "      <td>-0.586510</td>\n",
       "      <td>1.644479</td>\n",
       "      <td>-0.455016</td>\n",
       "      <td>-0.715717</td>\n",
       "      <td>0.363248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature     Precp        RH   StnPres        WS    WSGust     d_tmp  \\\n",
       "0    -1.405393 -0.246367 -0.342541  0.782879 -1.540053 -1.307154  2.639062   \n",
       "1    -0.965367 -0.246367 -0.586510  0.512573 -0.997534 -1.398144  2.521348   \n",
       "2    -0.585346 -0.179558 -0.220556  0.191585 -0.726275 -1.170668  0.520201   \n",
       "3    -1.165379 -0.246367 -1.074449  0.343632 -0.726275 -1.170668  0.912583   \n",
       "4    -1.565402 -0.246367 -1.562388  0.664620 -0.997534 -1.352649  1.422679   \n",
       "5    -1.625405 -0.246367 -0.342541  0.749091 -0.726275 -1.307154  0.912583   \n",
       "6    -1.165379 -0.246367 -0.220556  0.613938 -0.997534 -1.079678  2.011252   \n",
       "7    -1.045372 -0.246367 -0.342541  0.647726 -0.455016 -1.079678  1.618870   \n",
       "8    -1.705410 -0.246367 -1.074449  1.340385  0.901281 -0.351756 -0.892373   \n",
       "9    -1.525400 -0.246367 -0.586510  1.644479 -0.455016 -0.715717  0.363248   \n",
       "\n",
       "   g_marry  g_pray  g_funeral  ...  b_pray  b_funeral  b_business  month  \\\n",
       "0      1.0     1.0        0.0  ...     0.0        0.0         0.0    1.0   \n",
       "1      0.0     1.0        0.0  ...     0.0        1.0         1.0    1.0   \n",
       "2      0.0     1.0        0.0  ...     0.0        1.0         1.0    1.0   \n",
       "3      0.0     0.0        0.0  ...     0.0        1.0         1.0    1.0   \n",
       "4      0.0     1.0        1.0  ...     0.0        0.0         0.0    1.0   \n",
       "5      0.0     1.0        0.0  ...     0.0        0.0         0.0    1.0   \n",
       "6      0.0     0.0        1.0  ...     1.0        0.0         0.0    1.0   \n",
       "7      1.0     0.0        0.0  ...     0.0        1.0         0.0    1.0   \n",
       "8      0.0     1.0        0.0  ...     0.0        0.0         0.0    1.0   \n",
       "9      1.0     1.0        0.0  ...     0.0        1.0         1.0    1.0   \n",
       "\n",
       "   spring  valetine_west  mother  graduation  ghost  valetine_east  \n",
       "0     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "1     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "2     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "3     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "4     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "5     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "6     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "7     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "8     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "9     0.0            0.0     0.0         0.0    0.0            0.0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_data = pd.read_csv(fn_weather, encoding=\"utf-8\")\n",
    "lc_d = pd.read_csv(\"../lunar_celeb_date.csv\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "col_fix =  ['T.Max', 'T.Min', 'Precp','Temperature', 'RH', 'StnPres', 'WS', 'WSGust']\n",
    "# rm \"/\"\n",
    "for col in col_fix:\n",
    "    old = r_data[col]\n",
    "    new = []\n",
    "    for i in range(len(old)):\n",
    "        try:\n",
    "            new.append(float(old[i]))\n",
    "            tmp = float(old[i])\n",
    "        except ValueError:\n",
    "            new.append(tmp)\n",
    "    r_data[col] = new\n",
    "d_tmp = r_data['T.Max'] - r_data['T.Min']\n",
    "r_data[\"d_tmp\"]= d_tmp\n",
    "\n",
    "# extract_date\n",
    "d_data = r_data[\"Date\"]\n",
    "drop_c =[\"Date\",'T.Max', 'T.Min']\n",
    "r_data = r_data.drop(columns=drop_c)\n",
    "\n",
    "def to_zscore2(df):\n",
    "    col_x = df.columns.to_list()\n",
    "    mean = df.mean(axis=0)\n",
    "    std = df.std(axis=0)\n",
    "    for i in range(len(col_x)):\n",
    "        df[col_x[i]]=(df[col_x[i]]-mean[i])/std[i]\n",
    "    return  df , (mean, std)\n",
    "\n",
    "r_data, recordz = to_zscore2(r_data)\n",
    "r_data[\"Date\"] = d_data\n",
    "r_data = r_data.join(lc_d.set_index(\"date\"), on=\"Date\")\n",
    "r_data = r_data.drop(columns=[\"Date\"])\n",
    "r_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(r_data.shape)\n",
    "# print(d_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift1=28\n",
    "shift2=1\n",
    "\n",
    "dfs =[]\n",
    "arr_all =[]\n",
    "if shift2==0:\n",
    "    df_s = r_data.copy()\n",
    "else:\n",
    "    df_s = r_data.copy()\n",
    "    df_s = df_s.shift(periods=shift2)\n",
    "#     d_data = np.array(pd.DataFrame(d_data).shift(periods=shift2))\n",
    "#     add shift base\n",
    "arr_all = np.array(df_s)\n",
    "\n",
    "for i in range(1,shift1):\n",
    "    tp = np.array(df_s.shift(periods=i))\n",
    "    arr_all = np.concatenate((arr_all, tp), axis=1)\n",
    "df_all = pd.DataFrame(arr_all)\n",
    "df_all[\"date\"] = d_data\n",
    "df_all = df_all.dropna()\n",
    "df_all = df_all.reset_index()\n",
    "df_all = df_all.drop(columns=\"index\")\n",
    "\n",
    "# r_data = df_all\n",
    "\n",
    "# df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_data = df_all\n",
    "\n",
    "d_data = r_data[\"date\"]\n",
    "\n",
    "def trans_to_y_w(d_date):\n",
    "    year = int(d_date.split(\"-\")[0])\n",
    "    d_day = date(year,int(d_date.split(\"-\")[1]), int(d_date.split(\"-\")[2]))- date(year, 1, 1)\n",
    "    d_w = 1+ (d_day.days // 7)\n",
    "    if d_w ==53:\n",
    "        d_w = 52\n",
    "    result =  str(year) + \"_\" + str(d_w)\n",
    "\n",
    "    if d_day.days % 7 ==6:\n",
    "        return result\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "d_new = []\n",
    "for i in range(len(d_data)):\n",
    "    d_new.append(trans_to_y_w(d_data[i]))\n",
    "r_data[\"y_w\"] = d_new\n",
    "r_data = r_data.dropna()\n",
    "r_data = r_data.reset_index()\n",
    "r_data = r_data.drop(columns=\"index\")\n",
    "# r_data\n",
    "# d_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pbw = pd.read_csv(fn_price, encoding=\"utf-8\")\n",
    "# join x and y\n",
    "df_join = df_pbw.join(r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "df_join = df_join.dropna()\n",
    "df_join = df_join.reset_index()\n",
    "df_join = df_join.drop(columns=\"index\")\n",
    "# extract y info\n",
    "y_date = df_join[\"date\"]\n",
    "y_yw = df_join[\"y_w\"]\n",
    "y_raw = np.array(df_join[\"price_diff\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1265, 621)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d_t_dummy = [\"market\"]\n",
    "tmp_dum = pd.DataFrame()\n",
    "for col in d_t_dummy:\n",
    "    tmp_dum[col] = df_join[col]\n",
    "    dummy = pd.get_dummies(tmp_dum[col])\n",
    "    df_join = pd.concat([df_join, dummy], axis=1)\n",
    "drop_c = [\"market\",\"year\", \"week\",\"w_avg\", \"w_sale\", \"date\", \"y_w\", \"price_diff\"]\n",
    "# x finished\n",
    "x = np.array(df_join.drop(columns=drop_c))\n",
    "# x\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_price_diff describe:\n",
      "       y_price_diff\n",
      "count   1265.000000\n",
      "mean       0.028487\n",
      "std        0.275348\n",
      "min       -0.723768\n",
      "25%       -0.152215\n",
      "50%       -0.012461\n",
      "75%        0.168477\n",
      "max        1.566871\n",
      "======\n",
      "freq: [657 608]\n",
      "(1265, 621) 1265\n"
     ]
    }
   ],
   "source": [
    "# modify y\n",
    "# y_raw = np.array(df_join[\"price_diff\"])\n",
    "print(\"y_price_diff describe:\")\n",
    "print(pd.DataFrame(y_raw, columns=[\"y_price_diff\"]).describe())\n",
    "print(\"======\")\n",
    "def y_to_class(v):\n",
    "    t = 0\n",
    "    y_class_range = [0]\n",
    "#     for q in range(1,12):\n",
    "#         y_class_range.append(round((q*0.1-0.6),4))\n",
    "\n",
    "    for i in range(len(y_class_range)):\n",
    "        if (v >= y_class_range[i]):\n",
    "            t = i+1\n",
    "    return int(t)\n",
    "\n",
    "y_class = []\n",
    "\n",
    "for i in range(len(y_raw)):\n",
    "    y_class.append(y_to_class(y_raw[i]))\n",
    "print(\"freq:\",np.bincount(y_class))\n",
    "\n",
    "y = np.array(y_class)\n",
    "input_d = x.shape[1]\n",
    "print(x.shape,len(y))\n",
    "# x y ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2014 2015 2016 2017 2018]\n",
      "[235 255 255 260 260]\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "# y_date\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "y_year = []\n",
    "for i in range(len(y_yw)):\n",
    "    y_year.append(int(y_yw[i].split(\"_\")[0]))\n",
    "y_year = np.array(y_year)\n",
    "years, count = np.unique(np.array(y_year), return_counts=True)\n",
    "print(years)\n",
    "print(count)\n",
    "\n",
    "train = y_year[:]<=2017\n",
    "test = y_year[:]>2017\n",
    "\n",
    "x_train, y_train = x[train,:], y[train]\n",
    "x_test, y_test = x[test,:], y[test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dinp, epochs: 2 2\n",
      "53.08\n",
      "dinp, epochs: 2 4\n",
      "53.46\n",
      "dinp, epochs: 2 6\n",
      "61.54\n",
      "dinp, epochs: 4 2\n",
      "56.92\n",
      "dinp, epochs: 4 4\n",
      "53.85\n",
      "dinp, epochs: 4 6\n",
      "60.38\n",
      "dinp, epochs: 7 2\n",
      "59.62\n",
      "dinp, epochs: 7 4\n",
      "58.46\n",
      "dinp, epochs: 7 6\n",
      "55.0\n",
      "dinp, epochs: 9 2\n",
      "52.31\n",
      "dinp, epochs: 9 4\n",
      "58.08\n",
      "dinp, epochs: 9 6\n",
      "64.23\n"
     ]
    }
   ],
   "source": [
    "out_class_count = len(np.bincount(y))\n",
    "# shifts = 28\n",
    "result_table = []\n",
    "max_res = []\n",
    "acc_cf =0\n",
    "# dinp, epochs = (7,40)\n",
    "for dinp in [2,4,7,9]:\n",
    "    for epochs in [2,4,6]:\n",
    "        print(\"dinp, epochs:\",dinp, epochs)\n",
    "        #     epochs = 80\n",
    "        # xy_data = (x_train, y_train, x_test, y_test)\n",
    "        # x_train, y_train, x_test, y_test = xy_data\n",
    "        model = Sequential()\n",
    "        layer_0 = Dense(units =input_d//dinp, input_dim = input_d,\n",
    "                        kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "        model.add(layer_0)\n",
    "        model.add(Dropout(0.25))\n",
    "        layer_1 = Dense(units =(shift1+1),kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "        model.add(layer_1)\n",
    "        model.add(Dropout(0.25))\n",
    "        layer_out = Dense(units = out_class_count,kernel_initializer = \"random_normal\", \n",
    "                          activation = \"softmax\")\n",
    "        model.add(layer_out)\n",
    "        #     model.summary()\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "        train_history = model.fit(x = x_train, y = np_utils.to_categorical(y_train), \n",
    "                                  validation_split = 0.2, epochs =epochs, verbose = 0)\n",
    "        #     plt.plot(train_history.history[\"loss\"])\n",
    "        #     plt.plot(train_history.history[\"val_loss\"])\n",
    "        #     plt.title(\"Loss Graph\")\n",
    "        #     plt.legend(['loss', 'val_loss'], loc=\"upper left\")\n",
    "\n",
    "        #     model_test\n",
    "        pre = model.predict_classes(x_test)\n",
    "        acc = round(accuracy_score(y_test, pre)*100,2)\n",
    "        #         if acc > acc_cf:\n",
    "        #             max_res = dinp, epochs, acc\n",
    "        #             acc_cf = acc\n",
    "        #         result_table.append([dinp, epochs, acc])\n",
    "        print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_class_count = len(np.bincount(y))\n",
    "# shifts = 28\n",
    "# xy_data = (x_train, y_train, x_test, y_test)\n",
    "# def model_build(xy_data, input_d, shifts, epochs=60):\n",
    "#     x_train, y_train, x_test, y_test = xy_data\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     layer_0 = Dense(units =input_d//4, input_dim = input_d,\n",
    "#                     kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "#     model.add(layer_0)\n",
    "#     model.add(Dropout(0.25))\n",
    "#     layer_1 = Dense(units =shifts,kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "#     model.add(layer_1)\n",
    "#     model.add(Dropout(0.25))\n",
    "#     layer_out = Dense(units = out_class_count,kernel_initializer = \"random_normal\", \n",
    "#                       activation = \"softmax\")\n",
    "#     model.add(layer_out)\n",
    "#     #     model.summary()\n",
    "#     model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "#     train_history = model.fit(x = x_train, y = np_utils.to_categorical(y_train), \n",
    "#                               validation_split = 0.1, epochs =epochs, verbose = 2)\n",
    "    \n",
    "#     #     model_test\n",
    "#     pre = model.predict_classes(x_test)\n",
    "#     acc = round(accuracy_score(y_test, pre)*100,2)\n",
    "    \n",
    "#     return acc, model, train_history\n",
    "\n",
    "# acc_cf = 0\n",
    "\n",
    "# for epochs in range(5,80,5):\n",
    "#     print(\"epochs:\", epochs)\n",
    "#     acc, model ,train_history= model_build(xy_data, input_d, shifts, epochs=60)\n",
    "#     print(train_history)\n",
    "#     print(acc)\n",
    "#     if acc > acc_cf:\n",
    "#         acc_cf = acc\n",
    "#         bestmodel = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc\n",
    "# pd.DataFrame(result_table)\n",
    "# max_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# pre = model.predict_classes(x_test)\n",
    "# pd.DataFrame(confusion_matrix(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tr, y_tr = x[train,:], y_raw[train]\n",
    "# x_te, y_te = x[test,:], y_raw[test]\n",
    "# dinp, epochs = (10,400)\n",
    "# model = Sequential()\n",
    "# layer_0 = Dense(units =input_d//dinp, input_dim = input_d,\n",
    "#                 kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "# model.add(layer_0)\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# layer_0 = Dense(units =input_d//(dinp*5), input_dim = input_d,\n",
    "#                 kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "# model.add(layer_0)\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# layer_out = Dense(units = 1,kernel_initializer = \"random_normal\", \n",
    "#                   activation = \"linear\")\n",
    "# model.add(layer_out)\n",
    "# model.summary()\n",
    "# model.compile(loss=\"mse\",optimizer = \"adam\")\n",
    "# train_history = model.fit(x = x_tr, y = y_tr, \n",
    "#                           validation_split = 0.2, epochs =epochs, verbose = 0)\n",
    "# plt.plot(train_history.history[\"loss\"])\n",
    "# plt.plot(train_history.history[\"val_loss\"])\n",
    "# plt.title(\"Loss Graph\")\n",
    "# plt.legend(['loss', 'val_loss'], loc=\"upper left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = []\n",
    "# pre = model.predict(x_te)\n",
    "# for i in range(len(pre)):\n",
    "#     rs.append([pre[i][0], y_te[i]])\n",
    "# df_rs = pd.DataFrame(rs, columns=[\"pre\", \"ans\"])\n",
    "# # df_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
