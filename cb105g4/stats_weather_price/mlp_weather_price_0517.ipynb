{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import date, time, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "\n",
    "\n",
    "def data_select(fn_weather):\n",
    "    r_data = pd.read_csv(fn_weather, encoding=\"utf-8\")\n",
    "    col_fix =  ['T.Max', 'T.Min', 'Precp','Temperature', 'RH', 'StnPres', 'WS', 'WSGust']   \n",
    "    # rm \"/\"\n",
    "    for col in col_fix:\n",
    "        old = r_data[col]\n",
    "        new = []\n",
    "        for i in range(len(old)):\n",
    "            try:\n",
    "                new.append(float(old[i]))\n",
    "                tmp = float(old[i])\n",
    "            except ValueError:\n",
    "                new.append(tmp)\n",
    "        r_data[col] = new\n",
    "    d_tmp = r_data['T.Max'] - r_data['T.Min']\n",
    "    r_data[\"d_tmp\"]= d_tmp\n",
    "    \n",
    "    # extract_date\n",
    "    d_data = r_data[\"Date\"]\n",
    "    drop_c =[\"Date\",'T.Max', 'T.Min']\n",
    "    r_data = r_data.drop(columns=drop_c)\n",
    "\n",
    "    def to_zscore2(df):\n",
    "        col_x = df.columns.to_list()\n",
    "        mean = df.mean(axis=0)\n",
    "        std = df.std(axis=0)\n",
    "        for i in range(len(col_x)):\n",
    "            df[col_x[i]]=(df[col_x[i]]-mean[i])/std[i]\n",
    "        return  df , (mean, std)\n",
    "    \n",
    "    r_data, recordz = to_zscore2(r_data)\n",
    "    \n",
    "    return r_data, recordz , d_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_shift(r_data, d_data, fn_price ,shift1, shift2=0):\n",
    "    # shift and conbinde Data~ D-28 (D0~D-28)\n",
    "    dfs =[]\n",
    "    \n",
    "    shifts = shift1\n",
    "    \n",
    "    if shift2==0:\n",
    "        df_s = r_data.copy()\n",
    "    else:\n",
    "        df_s = r_data.copy()\n",
    "        df_s = df_s.shift(periods=shift2)\n",
    "        d_data = d_data[:(-shift2)]\n",
    "        \n",
    "#     add shift base\n",
    "    arr_all = np.array(df_s)\n",
    "    \n",
    "    for i in range(1,shifts+1):\n",
    "        tp = np.array(df_s.shift(periods=i))\n",
    "        arr_all = np.concatenate((arr_all, tp), axis=1)\n",
    "    \n",
    "    df_all = pd.DataFrame(arr_all)\n",
    "    \n",
    "    df_all = df_all.dropna()\n",
    "    df_all = df_all.reset_index()\n",
    "    df_all = df_all.drop(columns=\"index\")\n",
    "    d_data = d_data[:(-shifts)]\n",
    "    \n",
    "    r_data = df_all\n",
    "\n",
    "    d_date = d_data[0]\n",
    "    \n",
    "    def trans_to_y_w(d_date):\n",
    "        year = int(d_date.split(\"-\")[0])\n",
    "        d_day = date(year,int(d_date.split(\"-\")[1]), int(d_date.split(\"-\")[2]))- date(year, 1, 1)\n",
    "        d_w = 1+ (d_day.days // 7)\n",
    "        if d_w ==53:\n",
    "            d_w = 52\n",
    "        result =  str(year) + \"_\" + str(d_w)\n",
    "\n",
    "        if d_day.days % 7 ==6:\n",
    "            return result\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    d_new = []\n",
    "    for i in range(len(d_data)):\n",
    "        d_new.append(trans_to_y_w(d_data[i]))\n",
    "    r_data[\"y_w\"] = d_new\n",
    "    r_data = r_data.dropna()\n",
    "    \n",
    "    df_pbw = pd.read_csv(fn_price, encoding=\"utf-8\")\n",
    "    \n",
    "    drop_c = [\"year\", \"week\"]\n",
    "    df_pbw = df_pbw.drop(columns=drop_c)\n",
    "\n",
    "    df_join = df_pbw.join(r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "    df_join = df_join.dropna()\n",
    "    \n",
    "    d_t_dummy = [\"market\"]\n",
    "    date_info = pd.DataFrame()\n",
    "    for col in d_t_dummy:\n",
    "        date_info[col] = df_join[col]\n",
    "        dummy = pd.get_dummies(date_info[col])\n",
    "        df_join = pd.concat([df_join, dummy], axis=1)\n",
    "    \n",
    "    drop_c = [\"market\", \"w_avg\", \"w_sale\", \"y_w\",\"price_diff\"]\n",
    "    y_raw = np.array(df_join[\"price_diff\"])\n",
    "#     print(\"y_price_diff describe:\")\n",
    "#     print(df_join[\"price_diff\"].describe())\n",
    "#     print(\"======\")\n",
    "    df_join = df_join.drop(columns=drop_c)\n",
    "    \n",
    "    def y_to_class(v):\n",
    "        t = 0\n",
    "        y_class_range = []\n",
    "        for q in range(1,12):\n",
    "            y_class_range.append(round((q*0.1-0.6),4))\n",
    "\n",
    "        for i in range(len(y_class_range)):\n",
    "            if (v >= y_class_range[i]):\n",
    "                t = i+1\n",
    "        return int(t)\n",
    "\n",
    "    y_class = []\n",
    "\n",
    "    for i in range(len(y_raw)):\n",
    "        y_class.append(y_to_class(y_raw[i]))\n",
    "#     print(\"freq:\",np.bincount(y_class))\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = np.array(df_join)\n",
    "    y = y_class\n",
    "    input_d = x.shape[1]\n",
    "    \n",
    "    \n",
    "    return x, y, input_d\n",
    "\n",
    "\n",
    "def model_run(x, y, input_d, shifts, epochs=60):\n",
    "    \n",
    "    out_class_count = len(np.bincount(y))\n",
    "#     need_new_model_cut\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    model = Sequential()\n",
    "    layer_0 = Dense(units =input_d//4, input_dim = input_d,\n",
    "                    kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "    model.add(layer_0)\n",
    "    model.add(Dropout(0.25))\n",
    "    layer_1 = Dense(units =shifts,kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "    model.add(layer_1)\n",
    "    model.add(Dropout(0.25))\n",
    "    layer_out = Dense(units = out_class_count,kernel_initializer = \"random_normal\", \n",
    "                      activation = \"softmax\")\n",
    "    model.add(layer_out)\n",
    "#     model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    train_history = model.fit(x = x_train, y = np_utils.to_categorical(y_train), \n",
    "                              validation_split = 0.1, epochs =epochs, verbose = 0)\n",
    "    \n",
    "#     plt.plot(train_history.history[\"loss\"])\n",
    "#     plt.plot(train_history.history[\"val_loss\"])\n",
    "#     plt.title(\"Loss Graph\")\n",
    "#     plt.legend(['loss', 'val_loss'], loc=\"upper left\")\n",
    "    pre = model.predict_classes(x_test)\n",
    "    acc = round(accuracy_score(y_test, pre)*100,2)\n",
    "#     print(\"acc:\", round(accuracy_score(y_test, pre)*100,2),\"%\")\n",
    "\n",
    "    return acc, pd.DataFrame(confusion_matrix(y_test, pre)), model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C0F9L0_后里', 'Anthurium']\n",
      "data_shift_require= 28\n",
      "93.98\n",
      "datasaved\n"
     ]
    }
   ],
   "source": [
    "w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "p_list = glob.glob(\"../result/flower_price_byweek/*\")\n",
    "select_t = [(1,0),(3,2),(2,1),(2,3),(2,4)]\n",
    "\n",
    "\n",
    "def run_model_build(fn_weather,fn_price,shift2=0):\n",
    "    rs_data = []\n",
    "    test_w = fn_weather.split(\"\\\\\")[-1].split(\".\")[0] \n",
    "    test_p = fn_price.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "    rs_data.append(test_w)\n",
    "    rs_data.append(test_p)\n",
    "    print(rs_data)\n",
    "    r_data, recordz, d_data = data_selectv2(fn_weather)\n",
    "    rs_data.append(recordz)\n",
    "    tmp_acc =[]\n",
    "    acc_cf = 0\n",
    "    shift1 = 28\n",
    "    epochs = 80\n",
    "#     for shift1 in range(28,42+1,7):\n",
    "    print(\"data_shift_require=\", shift1)\n",
    "#         for epochs in range(80,120+1,20):\n",
    "    x, y, input_d = data_shift(r_data, d_data, fn_price , shift1, shift2)\n",
    "    acc, df_conf, model = model_run(x, y, input_d, shift1, epochs)\n",
    "    tmp_acc.append(acc)\n",
    "    if acc > acc_cf:\n",
    "        acc_cf = acc\n",
    "        best_model = model\n",
    "        set_info = (shift1, shift2, epochs)\n",
    "#                 print(\"epochs = \", epochs,\"acc = \",acc)\n",
    "    rs_data.append([acc_cf, set_info])        \n",
    "    rs_data.append(best_model)\n",
    "    return rs_data\n",
    "\n",
    "shift2 = 0\n",
    "# for st, flower in select_t:\n",
    "st, flower = select_t[0]\n",
    "fn_weather = w_list[st]\n",
    "fn_price = p_list[flower]\n",
    "\n",
    "result = run_model_build(fn_weather,fn_price, shift2)\n",
    "\n",
    "station, flower, recordz, bestmodel_info, bestmodel = result\n",
    "\n",
    "fn_model = \"./model_test0519/\"+ station + \"_\" + flower + \"_shift\"+ str(bestmodel_info[1][1]) + \\\n",
    "           \"_\" + str(bestmodel_info[1][0]) + \"_epo\" + str(bestmodel_info[1][2]) + \".h5\"\n",
    "fn_rec = \"./model_test0519/\"+ station + \".csv\"\n",
    "\n",
    "print(bestmodel_info[0])\n",
    "bestmodel.save(fn_model)\n",
    "df_rec = pd.DataFrame(recordz)\n",
    "df_rec[\"info\"] = [\"mean\", \"std\"]\n",
    "df_rec.to_csv(fn_rec, index=False, encoding=\"utf-8\")\n",
    "print(\"datasaved\")\n",
    "# df_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.11\n",
      "datasaved\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Temperature      24.226559\n",
       " Precp             3.687634\n",
       " RH               78.808065\n",
       " StnPres        1009.065968\n",
       " WS                0.967742\n",
       " WSGust            6.073172\n",
       " d_tmp             9.274247\n",
       " dtype: float64, Temperature     4.999712\n",
       " Precp          14.968040\n",
       " RH              8.197747\n",
       " StnPres         5.919220\n",
       " WS              0.368651\n",
       " WSGust          2.198037\n",
       " d_tmp           2.548539\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pred_weather_input(fn_weather, station_info):\n",
    "    r_data = pd.read_csv(fn_weather, encoding=\"utf-8\")\n",
    "    col_fix =  ['T.Max', 'T.Min', 'Precp','Temperature', 'RH', 'StnPres', 'WS', 'WSGust']   \n",
    "    # rm \"/\"\n",
    "    for col in col_fix:\n",
    "        old = r_data[col]\n",
    "        new = []\n",
    "        for i in range(len(old)):\n",
    "            try:\n",
    "                new.append(float(old[i]))\n",
    "                tmp = float(old[i])\n",
    "            except ValueError:\n",
    "                new.append(tmp)\n",
    "        r_data[col] = new\n",
    "    d_tmp = r_data['T.Max'] - r_data['T.Min']\n",
    "    r_data[\"d_tmp\"]= d_tmp\n",
    "    \n",
    "    # extract_date\n",
    "    d_data = r_data[\"Date\"]\n",
    "    drop_c =[\"Date\",'T.Max', 'T.Min']\n",
    "    r_data = r_data.drop(columns=drop_c)\n",
    "\n",
    "    def to_zscore2(df):\n",
    "        col_x = df.columns.to_list()\n",
    "        mean = df.mean(axis=0)\n",
    "        std = df.std(axis=0)\n",
    "        for i in range(len(col_x)):\n",
    "            df[col_x[i]]=(df[col_x[i]]-mean[i])/std[i]\n",
    "        return  df , (mean, std)\n",
    "    r_data, recordz = to_zscore2(r_data)\n",
    "    \n",
    "    r_data \n",
    "    d_data\n",
    "    pre_week, pre_flower, pre_market = station_info\n",
    "    \n",
    "    shift2 = 7 * (pre_week-1)\n",
    "\n",
    "\n",
    "\n",
    "# get model name \n",
    "    model_list = glob.glob(\"./model_test0519//*\"+pre_flower + \"*\")\n",
    "    for m in model_list:\n",
    "        keyw = \"shift\" + str((pre_week-1)*7)\n",
    "        if keyw in models:\n",
    "            model_fn = models\n",
    "# get shift 1 \n",
    "    shift1 = int(model_fn.split(\"\\\\\")[-1].split(\"_\")[3].replace(\"shift\",\"\"))\n",
    "\n",
    "def data_shift(r_data, d_data, fn_price shift1, shift2=0):\n",
    "    # shift and conbinde Data~ D-28 (D0~D-28)\n",
    "    dfs =[]\n",
    "    \n",
    "    shifts = shift1\n",
    "    \n",
    "    if shift2==0:\n",
    "        df_s = r_data.copy()\n",
    "    else:\n",
    "        df_s = r_data.copy()\n",
    "        df_s = df_s.shift(periods=shift2)\n",
    "        d_data = d_data[:(-shift2)]\n",
    "        \n",
    "#     add shift base\n",
    "    arr_all = np.array(df_s)\n",
    "    \n",
    "    for i in range(1,shifts+1):\n",
    "        tp = np.array(df_s.shift(periods=i))\n",
    "        arr_all = np.concatenate((arr_all, tp), axis=1)\n",
    "    \n",
    "    df_all = pd.DataFrame(arr_all)\n",
    "    \n",
    "    df_all = df_all.dropna()\n",
    "    df_all = df_all.reset_index()\n",
    "    df_all = df_all.drop(columns=\"index\")\n",
    "    d_data = d_data[:(-shifts)]\n",
    "    \n",
    "    r_data = df_all\n",
    "\n",
    "    d_date = d_data[0]\n",
    "    \n",
    "    def trans_to_y_w(d_date):\n",
    "        year = int(d_date.split(\"-\")[0])\n",
    "        d_day = date(year,int(d_date.split(\"-\")[1]), int(d_date.split(\"-\")[2]))- date(year, 1, 1)\n",
    "        d_w = 1+ (d_day.days // 7)\n",
    "        if d_w ==53:\n",
    "            d_w = 52\n",
    "        result =  str(year) + \"_\" + str(d_w)\n",
    "\n",
    "        if d_day.days % 7 ==6:\n",
    "            return result\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    d_new = []\n",
    "    for i in range(len(d_data)):\n",
    "        d_new.append(trans_to_y_w(d_data[i]))\n",
    "    r_data[\"y_w\"] = d_new\n",
    "    r_data = r_data.dropna()\n",
    "    \n",
    "    df_pbw = pd.read_csv(fn_price, encoding=\"utf-8\")\n",
    "    \n",
    "    drop_c = [\"year\", \"week\"]\n",
    "    df_pbw = df_pbw.drop(columns=drop_c)\n",
    "\n",
    "    df_join = df_pbw.join(r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "    df_join = df_join.dropna()\n",
    "    \n",
    "    d_t_dummy = [\"market\"]\n",
    "    date_info = pd.DataFrame()\n",
    "    for col in d_t_dummy:\n",
    "        date_info[col] = df_join[col]\n",
    "        dummy = pd.get_dummies(date_info[col])\n",
    "        df_join = pd.concat([df_join, dummy], axis=1)\n",
    "    \n",
    "    drop_c = [\"market\", \"w_avg\", \"w_sale\", \"y_w\",\"price_diff\"]\n",
    "    y_raw = np.array(df_join[\"price_diff\"])\n",
    "#     print(\"y_price_diff describe:\")\n",
    "#     print(df_join[\"price_diff\"].describe())\n",
    "#     print(\"======\")\n",
    "    df_join = df_join.drop(columns=drop_c)\n",
    "    \n",
    "    def y_to_class(v):\n",
    "        t = 0\n",
    "        y_class_range = []\n",
    "        for q in range(1,12):\n",
    "            y_class_range.append(round((q*0.1-0.6),4))\n",
    "\n",
    "        for i in range(len(y_class_range)):\n",
    "            if (v >= y_class_range[i]):\n",
    "                t = i+1\n",
    "        return int(t)\n",
    "\n",
    "    y_class = []\n",
    "\n",
    "    for i in range(len(y_raw)):\n",
    "        y_class.append(y_to_class(y_raw[i]))\n",
    "#     print(\"freq:\",np.bincount(y_class))\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = np.array(df_join)\n",
    "    y = y_class\n",
    "    input_d = x.shape[1]\n",
    "    \n",
    "    \n",
    "    return x, y, input_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.35\n"
     ]
    }
   ],
   "source": [
    "# def model_pred():\n",
    "opt_week = [1, 2]\n",
    "opt_flower = ['Anthurium', 'Chrysanthemum', 'OrientalLily', 'Eustoma', 'Rose']\n",
    "opt_market = [\"台北\", \"台中\", \"台南\", \"高雄\", \"彰化\"]\n",
    "model_select_info =  (opt_week[0], opt_flower[0], opt_market[0])\n",
    "# import weather data \n",
    "r_data, recordz , d_data = data_selectv2(fn_weather,fn_price)\n",
    "# shift and merger to  model input len\n",
    "\n",
    "# model predit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'Anthurium', '台北')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
