{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../result/merge_weather\\\\467480_嘉義.csv',\n",
       " '../result/merge_weather\\\\C0F9L0_后里.csv',\n",
       " '../result/merge_weather\\\\C0G650_員林.csv',\n",
       " '../result/merge_weather\\\\C0H960_草屯.csv',\n",
       " '../result/merge_weather\\\\C0K490_古坑.csv',\n",
       " '../result/merge_weather\\\\C0R590_里港.csv',\n",
       " '../result/merge_weather\\\\C0V360_內門.csv',\n",
       " '../result/merge_weather\\\\C0X060_下營.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "w_list= glob.glob(\"../result/merge_weather/*.csv\")\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "# 玫瑰 : 台中，彰化，雲林，嘉義，南投，高雄，屏東\n",
    "# 洋桔梗 : 南投，彰化，雲林，嘉義，台南\n",
    "# 大菊 : 彰化，雲林，南投\n",
    "# 火鶴花 : 台中，嘉義，南投，台南，高雄，屏東\n",
    "# 香水百合 :台中，南投，嘉義\n",
    "\n",
    "# flowers = []\n",
    "# for fn in get_f_list:\n",
    "#     flowers.append(fn.split(\"\\\\\")[-1].split(\"_\")[0])\n",
    "\n",
    "# flower = flowers[0]\n",
    "# fn_list = glob.glob(\"../result/merge_flower_price/*\" + flower + \"*.csv\")\n",
    "w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, time, datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "fn_raw = w_list[0]\n",
    "r_data = pd.read_csv(fn_raw, encoding=\"utf-8\")\n",
    "data_t_n = ['Temperature', 'RH', 'StnPres', 'WS', 'WSGust','d_tmp']\n",
    "col_fix =  ['T.Max', 'T.Min', 'Precp','Temperature', 'RH', 'StnPres', 'WS', 'WSGust']\n",
    "# rm \"/\"\n",
    "for col in col_fix:\n",
    "    old = r_data[col]\n",
    "    new = []\n",
    "    for i in range(len(old)):\n",
    "        try:\n",
    "            new.append(float(old[i]))\n",
    "            tmp = float(old[i])\n",
    "        except ValueError:\n",
    "            new.append(tmp)\n",
    "    r_data[col] = new\n",
    "rain  = r_data['Precp']\n",
    "# rain_class function\n",
    "def rain_c(precp):\n",
    "    rain_class=[0]\n",
    "    rain_tag = [\"no_rain\", \"rain\"]\n",
    "    result = 0\n",
    "    for d in rain_class:\n",
    "        if precp>d:\n",
    "            result = result + 1\n",
    "    return result\n",
    "\n",
    "rain_class=[]\n",
    "for precp in rain:\n",
    "    rain_class.append(rain_c(precp))\n",
    "# df_r[\"rain_class\"]=rain_class\n",
    "# print(\"0,<5,>5\",np.bincount(rain_class))\n",
    "d_tmp = r_data['T.Max'] - r_data['T.Min']\n",
    "d_data = r_data[\"Date\"]\n",
    "r_data[\"d_tmp\"]= d_tmp\n",
    "drop_c =[\"Date\",'T.Max', 'T.Min', 'Precp']\n",
    "r_data = r_data.drop(columns=drop_c)\n",
    "r_data[\"rain\"]= rain_class\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_data.describe()\n",
    "def to_zscore(df, col_x):\n",
    "#     df_tmp = df\n",
    "#     col = \"Temperature\"\n",
    "    for col in col_x:\n",
    "        df[col] = stats.zscore(df[col])\n",
    "        df[col] = np.round(df[col], decimals=4)\n",
    "# to_zscore(r_data, data_t_n)\n",
    "\n",
    "def to_zscore2(df):\n",
    "    col_x = df.columns.to_list()\n",
    "    mean = df.mean(axis=0)\n",
    "    std = df.std(axis=0)\n",
    "    for i in range(len(col_x)):\n",
    "        df[col_x[i]]=(df[col_x[i]]-mean[i])/std[i]\n",
    "    return (mean, std), df\n",
    "record, r_data = to_zscore2(r_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift and conbinde Data~ D-28 (D0~D-28)\n",
    "df_all = r_data.copy()\n",
    "arr_all = np.array(df_all)\n",
    "dfs =[]\n",
    "shifts = 28\n",
    "for i in range(1,shifts+1):\n",
    "    df_s = r_data.copy()\n",
    "    tp = np.array(df_s.shift(periods=i))\n",
    "    arr_all = np.concatenate((arr_all, tp), axis=1)\n",
    "\n",
    "df_all = pd.DataFrame(arr_all)\n",
    "df_all = df_all.dropna()\n",
    "df_all = df_all.reset_index()\n",
    "df_all = df_all.drop(columns=\"index\")\n",
    "d_data = d_data[:(-shifts)]\n",
    "r_data = df_all\n",
    "\n",
    "\n",
    "\n",
    "d_date = d_data[0]\n",
    "def trans_to_y_w(d_date):\n",
    "    year = int(d_date.split(\"-\")[0])\n",
    "    d_day = date(year,int(d_date.split(\"-\")[1]), int(d_date.split(\"-\")[2]))- date(year, 1, 1)\n",
    "    d_w = 1+ (d_day.days // 7)\n",
    "    if d_w ==53:\n",
    "        d_w = 52\n",
    "    result =  str(year) + \"_\" + str(d_w)\n",
    "    \n",
    "    if d_day.days % 7 ==6:\n",
    "        return result\n",
    "    else:\n",
    "        return None\n",
    "d_new = []\n",
    "for i in range(len(d_data)):\n",
    "    d_new.append(trans_to_y_w(d_data[i]))\n",
    "r_data[\"y_w\"] = d_new\n",
    "r_data = r_data.dropna()\n",
    "# r_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"../result/flower_price_byweek/Rose_pbyweek.csv\"\n",
    "df_pbw = pd.read_csv(fn, encoding=\"utf-8\")\n",
    "drop_c = [\"year\", \"week\"]\n",
    "df_pbw = df_pbw.drop(columns=drop_c)\n",
    "# df_pbw\n",
    "# len(df)\n",
    "df_join = df_pbw.join(r_data.set_index(\"y_w\"), on=\"y_w\")\n",
    "df_join = df_join.dropna()\n",
    "# df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_t_dummy = [\"market\"]\n",
    "date_info = pd.DataFrame()\n",
    "for col in d_t_dummy:\n",
    "    date_info[col] = df_join[col]\n",
    "    dummy = pd.get_dummies(date_info[col])\n",
    "    df_join = pd.concat([df_join, dummy], axis=1)\n",
    "drop_c = [\"market\", \"w_avg\", \"w_sale\", \"y_w\",\"price_diff\"]\n",
    "y_raw = np.array(df_join[\"price_diff\"])\n",
    "print(\"y_price_diff describe:\")\n",
    "print(df_join[\"price_diff\"].describe())\n",
    "print(\"======\")\n",
    "df_join = df_join.drop(columns=drop_c)\n",
    "# df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in range(1,12):\n",
    "#     print(round((q*0.1-0.6),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_to_class(v):\n",
    "    t = 0\n",
    "    y_class_range = []\n",
    "    for q in range(1,12):\n",
    "        y_class_range.append(round((q*0.1-0.6),4))\n",
    "        \n",
    "    for i in range(len(y_class_range)):\n",
    "        if (v >= y_class_range[i]):\n",
    "            t = i+1\n",
    "    return int(t)\n",
    "\n",
    "y_class = []\n",
    "\n",
    "for i in range(len(y_raw)):\n",
    "    y_class.append(y_to_class(y_raw[i]))\n",
    "print(\"freq:\",np.bincount(y_class))\n",
    "out_class_count = len(np.bincount(y_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df_join)\n",
    "y = y_class\n",
    "input_d = x.shape[1]\n",
    "print(input_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data corr testing\n",
    "# c = list(range(7)) + list(range(150,159))\n",
    "# df_t1 = pd.DataFrame(x[:,c])\n",
    "# df_t1[\"y\"] = y_class\n",
    "# # df_t1.corr()\n",
    "# cord = df_t1.corr()\n",
    "# c = cord.columns.to_list()\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# cax = ax.matshow(cord,cmap=\"OrRd\")\n",
    "# fig.colorbar(cax)\n",
    "\n",
    "# ax.set_xticklabels(['']+c)\n",
    "# ax.set_yticklabels(['']+c)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "# print(cord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "model = Sequential()\n",
    "layer_0 = Dense(units =input_d//4, input_dim = input_d,kernel_initializer = \"random_normal\",\n",
    "                activation = \"relu\")\n",
    "model.add(layer_0)\n",
    "model.add(Dropout(0.25))\n",
    "layer_1 = Dense(units =shifts,kernel_initializer = \"random_normal\", activation = \"relu\")\n",
    "model.add(layer_1)\n",
    "model.add(Dropout(0.25))\n",
    "layer_out = Dense(units = out_class_count,kernel_initializer = \"random_normal\",\n",
    "                  activation = \"softmax\")\n",
    "model.add(layer_out)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\", metrics = ['accuracy'])\n",
    "train_history = model.fit(x = x_train, y = np_utils.to_categorical(y_train),\n",
    "                          validation_split = 0.1, epochs =40, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history.history[\"loss\"])\n",
    "plt.plot(train_history.history[\"val_loss\"])\n",
    "plt.title(\"Loss Graph\")\n",
    "plt.legend(['loss', 'val_loss'], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "pre = model.predict_classes(x_test)\n",
    "print(\"acc:\", round(accuracy_score(y_test, pre)*100,2),\"%\")\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pre = model.predict_classes(x)\n",
    "# y_m = []\n",
    "# trans_c_m =[]\n",
    "# for q in range(1,13):\n",
    "#     trans_c_m.append(round((q*0.1-0.6),4))\n",
    "# #     print(q,trans_c_m[q])\n",
    "        \n",
    "# for i in range(len(y_pre)):\n",
    "#     y_m.append(trans_c_m[y_pre[i]])\n",
    "# y_real = y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# df[\"y_pre\"] = y_m\n",
    "# df[\"y_real\"] = y_real\n",
    "# # df.to_csv(\"bt_0515.csv\")\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.array([1,2,3])\n",
    "l.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
